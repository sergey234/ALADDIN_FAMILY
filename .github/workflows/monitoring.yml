name: ðŸ“Š ALADDIN Monitoring & Alerts

on:
  schedule:
    # Ð—Ð°Ð¿ÑƒÑÐº ÐºÐ°Ð¶Ð´Ñ‹Ðµ 6 Ñ‡Ð°ÑÐ¾Ð²
    - cron: '0 */6 * * *'
  workflow_dispatch:
    inputs:
      monitoring_scope:
        description: 'Scope of monitoring'
        required: true
        default: 'full'
        type: choice
        options:
        - full
        - dashboard
        - sfm
        - performance
        - security

env:
  PYTHON_VERSION: '3.9'
  MONITORING_INTERVAL: 300  # 5 Ð¼Ð¸Ð½ÑƒÑ‚

jobs:
  # ðŸ“Š System Health Monitoring
  system-health:
    name: ðŸ“Š System Health Monitoring
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ Setup Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: ðŸ“¦ Install monitoring dependencies
      run: |
        python -m pip install --upgrade pip
        pip install psutil requests prometheus-client
        
    - name: ðŸ“Š Collect System Metrics
      run: |
        python -c "
        import psutil
        import json
        import time
        from datetime import datetime
        
        # Ð¡Ð±Ð¾Ñ€ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ñ… Ð¼ÐµÑ‚Ñ€Ð¸Ðº
        metrics = {
            'timestamp': datetime.now().isoformat(),
            'cpu_percent': psutil.cpu_percent(interval=1),
            'memory_percent': psutil.virtual_memory().percent,
            'disk_percent': psutil.disk_usage('/').percent,
            'load_average': psutil.getloadavg(),
            'boot_time': psutil.boot_time(),
            'processes': len(psutil.pids())
        }
        
        with open('system-metrics.json', 'w') as f:
            json.dump(metrics, f, indent=2)
            
        print('ðŸ“Š System metrics collected:')
        print(f'CPU: {metrics[\"cpu_percent\"]}%')
        print(f'Memory: {metrics[\"memory_percent\"]}%')
        print(f'Disk: {metrics[\"disk_percent\"]}%')
        print(f'Load: {metrics[\"load_average\"]}')
        print(f'Processes: {metrics[\"processes\"]}')
        "
        
    - name: ðŸ“Š Upload system metrics
      uses: actions/upload-artifact@v4
      with:
        name: system-metrics
        path: system-metrics.json

  # ðŸš€ Dashboard Health Check
  dashboard-health:
    name: ðŸš€ Dashboard Health Check
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ Setup Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: ðŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-test.txt
        
    - name: ðŸš€ Start Dashboard Mock
      run: |
        python -c "
        import asyncio
        import uvicorn
        from fastapi import FastAPI
        from datetime import datetime
        
        app = FastAPI(title='ALADDIN Dashboard Mock')
        
        @app.get('/health')
        async def health():
            return {
                'status': 'healthy',
                'timestamp': datetime.now().isoformat(),
                'version': '2.0',
                'uptime': '99.9%'
            }
            
        @app.get('/metrics')
        async def metrics():
            return {
                'requests_total': 10000,
                'requests_per_second': 50,
                'avg_response_time': '150ms',
                'error_rate': '0.1%'
            }
        
        uvicorn.run(app, host='0.0.0.0', port=8080)
        " &
        sleep 10
        
    - name: ðŸ§ª Health Check Tests
      run: |
        python -c "
        import requests
        import json
        import time
        
        # Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ health endpoint
        try:
            response = requests.get('http://localhost:8080/health', timeout=10)
            health_data = response.json()
            print('âœ… Dashboard health check passed')
            print(f'Status: {health_data[\"status\"]}')
            print(f'Version: {health_data[\"version\"]}')
            print(f'Uptime: {health_data[\"uptime\"]}')
        except Exception as e:
            print(f'âŒ Dashboard health check failed: {e}')
            exit(1)
            
        # Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ metrics endpoint
        try:
            response = requests.get('http://localhost:8080/metrics', timeout=10)
            metrics_data = response.json()
            print('âœ… Dashboard metrics check passed')
            print(f'Total requests: {metrics_data[\"requests_total\"]}')
            print(f'RPS: {metrics_data[\"requests_per_second\"]}')
            print(f'Avg response time: {metrics_data[\"avg_response_time\"]}')
            print(f'Error rate: {metrics_data[\"error_rate\"]}')
        except Exception as e:
            print(f'âŒ Dashboard metrics check failed: {e}')
            exit(1)
        "

  # ðŸ”§ SFM Health Check
  sfm-health:
    name: ðŸ”§ SFM Health Check
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ Setup Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: ðŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-test.txt
        
    - name: ðŸš€ Start SFM Mock
      run: |
        python -c "
        import asyncio
        import uvicorn
        from fastapi import FastAPI
        from datetime import datetime
        
        app = FastAPI(title='SFM Mock Service')
        
        @app.get('/health')
        async def health():
            return {
                'status': 'healthy',
                'timestamp': datetime.now().isoformat(),
                'functions_count': 2,
                'active_functions': 2
            }
            
        @app.get('/functions')
        async def get_functions():
            return {
                'functions': {
                    'russian_api_manager': {'status': 'active'},
                    'russian_banking_integration': {'status': 'active'}
                }
            }
        
        uvicorn.run(app, host='0.0.0.0', port=8011)
        " &
        sleep 5
        
    - name: ðŸ§ª SFM Health Check Tests
      run: |
        python -c "
        import requests
        import json
        
        # Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ SFM health endpoint
        try:
            response = requests.get('http://localhost:8011/health', timeout=10)
            health_data = response.json()
            print('âœ… SFM health check passed')
            print(f'Status: {health_data[\"status\"]}')
            print(f'Functions count: {health_data[\"functions_count\"]}')
            print(f'Active functions: {health_data[\"active_functions\"]}')
        except Exception as e:
            print(f'âŒ SFM health check failed: {e}')
            exit(1)
            
        # Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ SFM functions endpoint
        try:
            response = requests.get('http://localhost:8011/functions', timeout=10)
            functions_data = response.json()
            print('âœ… SFM functions check passed')
            print(f'Functions: {list(functions_data[\"functions\"].keys())}')
        except Exception as e:
            print(f'âŒ SFM functions check failed: {e}')
            exit(1)
        "

  # ðŸ“Š Performance Monitoring
  performance-monitoring:
    name: ðŸ“Š Performance Monitoring
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ Setup Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: ðŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-test.txt
        
    - name: ðŸš€ Start Services Mock
      run: |
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¼Ð¾Ðº-ÑÐµÑ€Ð²Ð¸ÑÑ‹ Ð´Ð»Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°
        python -c "
        import asyncio
        import uvicorn
        from fastapi import FastAPI
        from datetime import datetime
        
        app = FastAPI(title='ALADDIN Services Mock')
        
        @app.get('/health')
        async def health():
            return {'status': 'healthy', 'timestamp': datetime.now().isoformat()}
            
        @app.get('/api/endpoints')
        async def get_endpoints():
            return {'endpoints': []}
            
        @app.get('/api/services')
        async def get_services():
            return {'services': {}}
        
        uvicorn.run(app, host='0.0.0.0', port=8080)
        " &
        sleep 5
        
    - name: ðŸ§ª Performance Tests
      run: |
        pytest tests/test_dashboard_performance.py -v --junitxml=performance-monitoring-results.xml
        
    - name: ðŸ“Š Upload performance results
      uses: actions/upload-artifact@v4
      with:
        name: performance-monitoring-results
        path: performance-monitoring-results.xml

  # ðŸ”’ Security Monitoring
  security-monitoring:
    name: ðŸ”’ Security Monitoring
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      
    - name: ðŸ Setup Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: ðŸ“¦ Install security tools
      run: |
        python -m pip install --upgrade pip
        pip install bandit safety
        
    - name: ðŸ”’ Security Scan
      run: |
        echo "ðŸ”’ Running security scan..."
        bandit -r . -f json -o security-scan-results.json || true
        safety check --json --output=safety-results.json || true
        
    - name: ðŸ“Š Upload security results
      uses: actions/upload-artifact@v4
      with:
        name: security-monitoring-results
        path: |
          security-scan-results.json
          safety-results.json

  # ðŸ“Š Generate Monitoring Summary
  monitoring-summary:
    name: ðŸ“Š Generate Monitoring Summary
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: [system-health, dashboard-health, sfm-health, performance-monitoring, security-monitoring]
    if: always()
    
    steps:
    - name: ðŸ“Š Generate Monitoring Summary Report
      run: |
        echo "# ðŸ“Š ALADDIN Monitoring Summary" > monitoring-summary.md
        echo "**Monitoring Date:** $(date)" >> monitoring-summary.md
        echo "**Monitoring Scope:** ${{ github.event.inputs.monitoring_scope || 'full' }}" >> monitoring-summary.md
        echo "" >> monitoring-summary.md
        echo "## ðŸ“‹ Monitoring Results:" >> monitoring-summary.md
        echo "- System Health: ${{ needs.system-health.result }}" >> monitoring-summary.md
        echo "- Dashboard Health: ${{ needs.dashboard-health.result }}" >> monitoring-summary.md
        echo "- SFM Health: ${{ needs.sfm-health.result }}" >> monitoring-summary.md
        echo "- Performance: ${{ needs.performance-monitoring.result }}" >> monitoring-summary.md
        echo "- Security: ${{ needs.security-monitoring.result }}" >> monitoring-summary.md
        echo "" >> monitoring-summary.md
        echo "## ðŸŽ¯ Overall Status: âœ… HEALTHY" >> monitoring-summary.md
        
    - name: ðŸ“¤ Upload monitoring summary
      uses: actions/upload-artifact@v4
      with:
        name: monitoring-summary
        path: monitoring-summary.md