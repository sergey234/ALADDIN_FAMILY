# üé§ –ì–æ–ª–æ—Å–æ–≤–æ–µ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ - –ü–ª–∞–Ω –†–µ–∞–ª–∏–∑–∞—Ü–∏–∏

## üéØ **–ß–¢–û –≠–¢–û –¢–ê–ö–û–ï?**
**–ì–æ–ª–æ—Å–æ–≤–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ** - —ç—Ç–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —É–ø—Ä–∞–≤–ª—è—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º –≥–æ–ª–æ—Å–æ–º. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –≥–æ–≤–æ—Ä–∏—Ç—å –∫–æ–º–∞–Ω–¥—ã, –∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏—Ö –ø–æ–Ω–∏–º–∞–µ—Ç –∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç. –≠—Ç–æ –∫–∞–∫ –≥–æ–ª–æ—Å–æ–≤–æ–π –ø–æ–º–æ—â–Ω–∏–∫, –Ω–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è —Å–µ–º–µ–π–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.

## ‚ö†Ô∏è **–ó–ê–ß–ï–ú –ù–£–ñ–ù–û?**
- **–£–¥–æ–±—Å—Ç–≤–æ** - –æ—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è –ø–æ–∂–∏–ª—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
- **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å** - —Ä—É–∫–∏ —Å–≤–æ–±–æ–¥–Ω—ã –¥–ª—è –¥—Ä—É–≥–∏—Ö –¥–µ–ª
- **–î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å** - –ø–æ–º–æ—â—å –ª—é–¥—è–º —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏
- **–°–æ–≤—Ä–µ–º–µ–Ω–Ω–æ—Å—Ç—å** - —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–Ω–¥–∞–º

## üì± **–†–ï–ê–õ–ò–ó–ê–¶–ò–Ø –î–õ–Ø iOS (Speech Framework)**

### –®–∞–≥ 1: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Speech Recognition
```swift
// mobile/ios/Voice/SpeechManager.swift
import Speech
import AVFoundation

class SpeechManager: NSObject {
    private let speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "ru-RU"))
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?
    private let audioEngine = AVAudioEngine()
    
    var isListening = false
    var onCommandRecognized: ((VoiceCommand) -> Void)?
    
    // –ó–∞–ø—Ä–æ—Å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–π
    func requestPermissions(completion: @escaping (Bool) -> Void) {
        SFSpeechRecognizer.requestAuthorization { authStatus in
            DispatchQueue.main.async {
                completion(authStatus == .authorized)
            }
        }
    }
    
    // –ù–∞—á–∞–ª–æ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è
    func startListening() {
        guard !isListening else { return }
        
        do {
            try startAudioSession()
            try startRecognition()
            isListening = true
        } catch {
            print("Speech recognition error: \(error)")
        }
    }
    
    // –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è
    func stopListening() {
        audioEngine.stop()
        recognitionRequest?.endAudio()
        recognitionTask?.cancel()
        isListening = false
    }
    
    private func startAudioSession() throws {
        let audioSession = AVAudioSession.sharedInstance()
        try audioSession.setCategory(.record, mode: .measurement, options: .duckOthers)
        try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
    }
    
    private func startRecognition() throws {
        recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
        
        guard let recognitionRequest = recognitionRequest else {
            throw SpeechError.recognitionRequestFailed
        }
        
        recognitionRequest.shouldReportPartialResults = true
        
        let inputNode = audioEngine.inputNode
        recognitionTask = speechRecognizer?.recognitionTask(with: recognitionRequest) { [weak self] result, error in
            if let result = result {
                self?.processRecognitionResult(result)
            }
            
            if error != nil {
                self?.stopListening()
            }
        }
        
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { buffer, _ in
            recognitionRequest.append(buffer)
        }
        
        audioEngine.prepare()
        try audioEngine.start()
    }
    
    private func processRecognitionResult(_ result: SFSpeechRecognitionResult) {
        let command = VoiceCommandParser.parse(result.bestTranscription.formattedString)
        onCommandRecognized?(command)
    }
}
```

### –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ Voice Command Parser
```swift
// mobile/ios/Voice/VoiceCommandParser.swift
class VoiceCommandParser {
    static func parse(_ text: String) -> VoiceCommand {
        let lowercaseText = text.lowercased()
        
        // –ö–æ–º–∞–Ω–¥—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        if lowercaseText.contains("–≤–∫–ª—é—á–∏ –∑–∞—â–∏—Ç—É") || lowercaseText.contains("–∞–∫—Ç–∏–≤–∏—Ä—É–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å") {
            return .enableSecurity
        }
        
        if lowercaseText.contains("–≤—ã–∫–ª—é—á–∏ –∑–∞—â–∏—Ç—É") || lowercaseText.contains("–¥–µ–∞–∫—Ç–∏–≤–∏—Ä—É–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å") {
            return .disableSecurity
        }
        
        // VPN –∫–æ–º–∞–Ω–¥—ã
        if lowercaseText.contains("–≤–∫–ª—é—á–∏ vpn") || lowercaseText.contains("–ø–æ–¥–∫–ª—é—á–∏ vpn") {
            return .enableVPN
        }
        
        if lowercaseText.contains("–≤—ã–∫–ª—é—á–∏ vpn") || lowercaseText.contains("–æ—Ç–∫–ª—é—á–∏ vpn") {
            return .disableVPN
        }
        
        // –°–µ–º–µ–π–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã
        if lowercaseText.contains("–ø–æ–∫–∞–∂–∏ —Å–µ–º—å—é") || lowercaseText.contains("—Å–µ–º–µ–π–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏") {
            return .showFamily
        }
        
        if lowercaseText.contains("–¥–æ–±–∞–≤—å —Ä–µ–±–µ–Ω–∫–∞") || lowercaseText.contains("–Ω–æ–≤—ã–π —Ä–µ–±–µ–Ω–æ–∫") {
            return .addChild
        }
        
        // AI –ø–æ–º–æ—â–Ω–∏–∫
        if lowercaseText.contains("–ø–æ–º–æ—â—å") || lowercaseText.contains("ai –ø–æ–º–æ—â–Ω–∏–∫") {
            return .openAIAssistant
        }
        
        if lowercaseText.contains("—á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç") || lowercaseText.contains("—Å—Ç–∞—Ç—É—Å") {
            return .showStatus
        }
        
        // –ê–Ω–∞–ª–∏—Ç–∏–∫–∞
        if lowercaseText.contains("–ø–æ–∫–∞–∂–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É") || lowercaseText.contains("–∞–Ω–∞–ª–∏—Ç–∏–∫–∞") {
            return .showAnalytics
        }
        
        // –ù–∞—Å—Ç—Ä–æ–π–∫–∏
        if lowercaseText.contains("–Ω–∞—Å—Ç—Ä–æ–π–∫–∏") || lowercaseText.contains("–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è") {
            return .openSettings
        }
        
        return .unknown
    }
}

enum VoiceCommand {
    case enableSecurity
    case disableSecurity
    case enableVPN
    case disableVPN
    case showFamily
    case addChild
    case openAIAssistant
    case showStatus
    case showAnalytics
    case openSettings
    case unknown
}
```

### –®–∞–≥ 3: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å UI
```swift
// mobile/ios/UI/VoiceControlView.swift
class VoiceControlView: UIView {
    @IBOutlet weak var voiceButton: UIButton!
    @IBOutlet weak var statusLabel: UILabel!
    @IBOutlet weak var commandLabel: UILabel!
    
    private let speechManager = SpeechManager()
    
    override func awakeFromNib() {
        super.awakeFromNib()
        setupVoiceControl()
    }
    
    private func setupVoiceControl() {
        speechManager.onCommandRecognized = { [weak self] command in
            DispatchQueue.main.async {
                self?.handleVoiceCommand(command)
            }
        }
        
        voiceButton.addTarget(self, action: #selector(voiceButtonTapped), for: .touchUpInside)
    }
    
    @objc private func voiceButtonTapped() {
        if speechManager.isListening {
            speechManager.stopListening()
            updateUI(isListening: false)
        } else {
            speechManager.startListening()
            updateUI(isListening: true)
        }
    }
    
    private func updateUI(isListening: Bool) {
        voiceButton.setTitle(isListening ? "üõë" : "üé§", for: .normal)
        statusLabel.text = isListening ? "–°–ª—É—à–∞—é..." : "–ù–∞–∂–º–∏—Ç–µ –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è"
        commandLabel.text = ""
    }
    
    private func handleVoiceCommand(_ command: VoiceCommand) {
        commandLabel.text = "–ö–æ–º–∞–Ω–¥–∞: \(commandDescription(command))"
        
        // –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã
        switch command {
        case .enableSecurity:
            // –í–∫–ª—é—á–∏—Ç—å –∑–∞—â–∏—Ç—É
            break
        case .disableSecurity:
            // –í—ã–∫–ª—é—á–∏—Ç—å –∑–∞—â–∏—Ç—É
            break
        case .enableVPN:
            // –í–∫–ª—é—á–∏—Ç—å VPN
            break
        case .disableVPN:
            // –í—ã–∫–ª—é—á–∏—Ç—å VPN
            break
        case .showFamily:
            // –ü–æ–∫–∞–∑–∞—Ç—å —Å–µ–º–µ–π–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏
            break
        case .addChild:
            // –î–æ–±–∞–≤–∏—Ç—å —Ä–µ–±–µ–Ω–∫–∞
            break
        case .openAIAssistant:
            // –û—Ç–∫—Ä—ã—Ç—å AI –ø–æ–º–æ—â–Ω–∏–∫–∞
            break
        case .showStatus:
            // –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å
            break
        case .showAnalytics:
            // –ü–æ–∫–∞–∑–∞—Ç—å –∞–Ω–∞–ª–∏—Ç–∏–∫—É
            break
        case .openSettings:
            // –û—Ç–∫—Ä—ã—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            break
        case .unknown:
            commandLabel.text = "–ö–æ–º–∞–Ω–¥–∞ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞"
        }
    }
    
    private func commandDescription(_ command: VoiceCommand) -> String {
        switch command {
        case .enableSecurity: return "–í–∫–ª—é—á–∏—Ç—å –∑–∞—â–∏—Ç—É"
        case .disableSecurity: return "–í—ã–∫–ª—é—á–∏—Ç—å –∑–∞—â–∏—Ç—É"
        case .enableVPN: return "–í–∫–ª—é—á–∏—Ç—å VPN"
        case .disableVPN: return "–í—ã–∫–ª—é—á–∏—Ç—å VPN"
        case .showFamily: return "–ü–æ–∫–∞–∑–∞—Ç—å —Å–µ–º—å—é"
        case .addChild: return "–î–æ–±–∞–≤–∏—Ç—å —Ä–µ–±–µ–Ω–∫–∞"
        case .openAIAssistant: return "AI –ø–æ–º–æ—â–Ω–∏–∫"
        case .showStatus: return "–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å"
        case .showAnalytics: return "–ü–æ–∫–∞–∑–∞—Ç—å –∞–Ω–∞–ª–∏—Ç–∏–∫—É"
        case .openSettings: return "–û—Ç–∫—Ä—ã—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏"
        case .unknown: return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞"
        }
    }
}
```

## ü§ñ **–†–ï–ê–õ–ò–ó–ê–¶–ò–Ø –î–õ–Ø ANDROID (Speech Recognition API)**

### –®–∞–≥ 1: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Speech Recognition
```kotlin
// mobile/android/Voice/SpeechManager.kt
class SpeechManager @Inject constructor(
    private val context: Context
) {
    private val speechRecognizer = SpeechRecognizer.createSpeechRecognizer(context)
    private var isListening = false
    
    var onCommandRecognized: ((VoiceCommand) -> Unit)? = null
    
    init {
        setupSpeechRecognizer()
    }
    
    private fun setupSpeechRecognizer() {
        speechRecognizer.setRecognitionListener(object : RecognitionListener {
            override fun onReadyForSpeech(params: Bundle?) {
                // –ì–æ—Ç–æ–≤ –∫ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—é
            }
            
            override fun onBeginningOfSpeech() {
                // –ù–∞—á–∞–ª–æ —Ä–µ—á–∏
            }
            
            override fun onRmsChanged(rmsdB: Float) {
                // –£—Ä–æ–≤–µ–Ω—å –∑–≤—É–∫–∞
            }
            
            override fun onBufferReceived(buffer: ByteArray?) {
                // –ë—É—Ñ–µ—Ä –∑–≤—É–∫–∞
            }
            
            override fun onEndOfSpeech() {
                // –ö–æ–Ω–µ—Ü —Ä–µ—á–∏
            }
            
            override fun onError(error: Int) {
                isListening = false
                when (error) {
                    SpeechRecognizer.ERROR_AUDIO -> Log.e("Speech", "Audio error")
                    SpeechRecognizer.ERROR_CLIENT -> Log.e("Speech", "Client error")
                    SpeechRecognizer.ERROR_INSUFFICIENT_PERMISSIONS -> Log.e("Speech", "Insufficient permissions")
                    SpeechRecognizer.ERROR_NETWORK -> Log.e("Speech", "Network error")
                    SpeechRecognizer.ERROR_NETWORK_TIMEOUT -> Log.e("Speech", "Network timeout")
                    SpeechRecognizer.ERROR_NO_MATCH -> Log.e("Speech", "No match")
                    SpeechRecognizer.ERROR_RECOGNIZER_BUSY -> Log.e("Speech", "Recognizer busy")
                    SpeechRecognizer.ERROR_SERVER -> Log.e("Speech", "Server error")
                    SpeechRecognizer.ERROR_SPEECH_TIMEOUT -> Log.e("Speech", "Speech timeout")
                }
            }
            
            override fun onResults(results: Bundle?) {
                val matches = results?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                if (!matches.isNullOrEmpty()) {
                    val command = VoiceCommandParser.parse(matches[0])
                    onCommandRecognized?.invoke(command)
                }
                isListening = false
            }
            
            override fun onPartialResults(partialResults: Bundle?) {
                // –ß–∞—Å—Ç–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            }
            
            override fun onEvent(eventType: Int, params: Bundle?) {
                // –°–æ–±—ã—Ç–∏—è
            }
        })
    }
    
    // –ù–∞—á–∞–ª–æ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è
    fun startListening() {
        if (isListening) return
        
        val intent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
            putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
            putExtra(RecognizerIntent.EXTRA_LANGUAGE, "ru-RU")
            putExtra(RecognizerIntent.EXTRA_PROMPT, "–ì–æ–≤–æ—Ä–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É...")
        }
        
        speechRecognizer.startListening(intent)
        isListening = true
    }
    
    // –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è
    fun stopListening() {
        speechRecognizer.stopListening()
        isListening = false
    }
    
    // –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤
    fun destroy() {
        speechRecognizer.destroy()
    }
}
```

### –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ Voice Command Parser
```kotlin
// mobile/android/Voice/VoiceCommandParser.kt
object VoiceCommandParser {
    fun parse(text: String): VoiceCommand {
        val lowercaseText = text.lowercase()
        
        return when {
            lowercaseText.contains("–≤–∫–ª—é—á–∏ –∑–∞—â–∏—Ç—É") || lowercaseText.contains("–∞–∫—Ç–∏–≤–∏—Ä—É–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å") -> 
                VoiceCommand.ENABLE_SECURITY
            lowercaseText.contains("–≤—ã–∫–ª—é—á–∏ –∑–∞—â–∏—Ç—É") || lowercaseText.contains("–¥–µ–∞–∫—Ç–∏–≤–∏—Ä—É–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å") -> 
                VoiceCommand.DISABLE_SECURITY
            lowercaseText.contains("–≤–∫–ª—é—á–∏ vpn") || lowercaseText.contains("–ø–æ–¥–∫–ª—é—á–∏ vpn") -> 
                VoiceCommand.ENABLE_VPN
            lowercaseText.contains("–≤—ã–∫–ª—é—á–∏ vpn") || lowercaseText.contains("–æ—Ç–∫–ª—é—á–∏ vpn") -> 
                VoiceCommand.DISABLE_VPN
            lowercaseText.contains("–ø–æ–∫–∞–∂–∏ —Å–µ–º—å—é") || lowercaseText.contains("—Å–µ–º–µ–π–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏") -> 
                VoiceCommand.SHOW_FAMILY
            lowercaseText.contains("–¥–æ–±–∞–≤—å —Ä–µ–±–µ–Ω–∫–∞") || lowercaseText.contains("–Ω–æ–≤—ã–π —Ä–µ–±–µ–Ω–æ–∫") -> 
                VoiceCommand.ADD_CHILD
            lowercaseText.contains("–ø–æ–º–æ—â—å") || lowercaseText.contains("ai –ø–æ–º–æ—â–Ω–∏–∫") -> 
                VoiceCommand.OPEN_AI_ASSISTANT
            lowercaseText.contains("—á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç") || lowercaseText.contains("—Å—Ç–∞—Ç—É—Å") -> 
                VoiceCommand.SHOW_STATUS
            lowercaseText.contains("–ø–æ–∫–∞–∂–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É") || lowercaseText.contains("–∞–Ω–∞–ª–∏—Ç–∏–∫–∞") -> 
                VoiceCommand.SHOW_ANALYTICS
            lowercaseText.contains("–Ω–∞—Å—Ç—Ä–æ–π–∫–∏") || lowercaseText.contains("–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è") -> 
                VoiceCommand.OPEN_SETTINGS
            else -> VoiceCommand.UNKNOWN
        }
    }
}

enum class VoiceCommand {
    ENABLE_SECURITY,
    DISABLE_SECURITY,
    ENABLE_VPN,
    DISABLE_VPN,
    SHOW_FAMILY,
    ADD_CHILD,
    OPEN_AI_ASSISTANT,
    SHOW_STATUS,
    SHOW_ANALYTICS,
    OPEN_SETTINGS,
    UNKNOWN
}
```

## üìã **–ü–õ–ê–ù –í–ù–ï–î–†–ï–ù–ò–Ø (2 –Ω–µ–¥–µ–ª–∏)**

### –ù–µ–¥–µ–ª—è 1: –ë–∞–∑–æ–≤–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
- [ ] –î–µ–Ω—å 1-2: –ù–∞—Å—Ç—Ä–æ–∏—Ç—å Speech Recognition –¥–ª—è iOS –∏ Android
- [ ] –î–µ–Ω—å 3-4: –°–æ–∑–¥–∞—Ç—å Voice Command Parser
- [ ] –î–µ–Ω—å 5-7: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –±–∞–∑–æ–≤—ã–µ –∫–æ–º–∞–Ω–¥—ã

### –ù–µ–¥–µ–ª—è 2: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
- [ ] –î–µ–Ω—å 1-2: –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å UI
- [ ] –î–µ–Ω—å 3-4: –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –∫–æ–º–∞–Ω–¥—ã
- [ ] –î–µ–Ω—å 5-7: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

## üé® **UI –ö–û–ú–ü–û–ù–ï–ù–¢–´**

### Floating Voice Button
```swift
// iOS
class FloatingVoiceButton: UIButton {
    override func awakeFromNib() {
        super.awakeFromNib()
        setupFloatingButton()
    }
    
    private func setupFloatingButton() {
        layer.cornerRadius = frame.width / 2
        layer.shadowColor = UIColor.black.cgColor
        layer.shadowOffset = CGSize(width: 0, height: 2)
        layer.shadowOpacity = 0.3
        layer.shadowRadius = 4
    }
}
```

```kotlin
// Android
class FloatingVoiceButton @JvmOverloads constructor(
    context: Context,
    attrs: AttributeSet? = null
) : FloatingActionButton(context, attrs) {
    
    init {
        setupFloatingButton()
    }
    
    private fun setupFloatingButton() {
        setImageResource(R.drawable.ic_mic)
        setOnClickListener { toggleListening() }
    }
}
```

## ‚ö†Ô∏è **–í–ê–ñ–ù–´–ï –ú–û–ú–ï–ù–¢–´**

### ‚úÖ **–ü–õ–Æ–°–´:**
- –£–¥–æ–±—Å—Ç–≤–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
- –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –¥–ª—è –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
- –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
- –ü–æ–º–æ—â—å –ø–æ–∂–∏–ª—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º

### ‚ö†Ô∏è **–ú–ò–ù–£–°–´:**
- –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
- –ü—Ä–æ–±–ª–µ–º—ã —Å —à—É–º–æ–º
- –ù–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
- –ü–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –±–∞—Ç–∞—Ä–µ–∏

## üìä **–ú–ï–¢–†–ò–ö–ò –£–°–ü–ï–•–ê**
- [ ] 90%+ —Ç–æ—á–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∫–æ–º–∞–Ω–¥
- [ ] <2 —Å–µ–∫—É–Ω–¥—ã –≤—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞
- [ ] 80%+ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É—é—Ç –≥–æ–ª–æ—Å–æ–≤–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
- [ ] <5% –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π

---

*–û—Ç–ª–∏—á–Ω–æ–µ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ —Å–µ–º–µ–π–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è!*

