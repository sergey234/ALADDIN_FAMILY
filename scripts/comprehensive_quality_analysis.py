#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞ –≤—Å–µ—Ö —Ñ—É–Ω–∫—Ü–∏–π –≤ SafeFunctionManager
–ü—Ä–æ–≤–µ—Ä–∫–∞: PEP8, SOLID, DRY, –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å, –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
"""

import os
import sys
import ast
import re
import subprocess
from datetime import datetime
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append('/Users/sergejhlystov/ALADDIN_NEW')

class CodeQualityAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞"""
    
    def __init__(self):
        self.base_path = "/Users/sergejhlystov/ALADDIN_NEW"
        self.issues = []
        self.function_analysis = {}
        self.overall_score = 0
        
    def analyze_file(self, file_path):
        """–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # –ü–∞—Ä—Å–∏–Ω–≥ AST
            tree = ast.parse(content)
            
            file_analysis = {
                'file_path': file_path,
                'pep8_issues': [],
                'solid_issues': [],
                'dry_issues': [],
                'security_issues': [],
                'architecture_issues': [],
                'docstring_issues': [],
                'complexity_issues': [],
                'readability_issues': [],
                'score': 0
            }
            
            # –ê–Ω–∞–ª–∏–∑ PEP8
            self._analyze_pep8(content, file_analysis)
            
            # –ê–Ω–∞–ª–∏–∑ SOLID –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤
            self._analyze_solid(tree, file_analysis)
            
            # –ê–Ω–∞–ª–∏–∑ DRY –ø—Ä–∏–Ω—Ü–∏–ø–∞
            self._analyze_dry(content, file_analysis)
            
            # –ê–Ω–∞–ª–∏–∑ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
            self._analyze_security(content, file_analysis)
            
            # –ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
            self._analyze_architecture(tree, file_analysis)
            
            # –ê–Ω–∞–ª–∏–∑ docstrings
            self._analyze_docstrings(tree, file_analysis)
            
            # –ê–Ω–∞–ª–∏–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
            self._analyze_complexity(tree, file_analysis)
            
            # –ê–Ω–∞–ª–∏–∑ —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            self._analyze_readability(content, file_analysis)
            
            # –ü–æ–¥—Å—á–µ—Ç –æ–±—â–µ–≥–æ –±–∞–ª–ª–∞
            self._calculate_score(file_analysis)
            
            return file_analysis
            
        except Exception as e:
            return {
                'file_path': file_path,
                'error': str(e),
                'score': 0
            }
    
    def _analyze_pep8(self, content, analysis):
        """–ê–Ω–∞–ª–∏–∑ PEP8 –Ω–∞—Ä—É—à–µ–Ω–∏–π"""
        lines = content.split('\n')
        
        for i, line in enumerate(lines, 1):
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã —Å—Ç—Ä–æ–∫–∏
            if len(line) > 120:
                analysis['pep8_issues'].append(f"Line {i}: Line too long ({len(line)} > 120)")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—Ç—É–ø–æ–≤
            if line.strip() and not line.startswith(' ') and not line.startswith('\t'):
                if i > 1 and lines[i-2].strip().endswith(':'):
                    if not line.startswith('    '):
                        analysis['pep8_issues'].append(f"Line {i}: Expected 4 spaces for indentation")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–±–µ–ª–æ–≤
            if line.strip().endswith(' '):
                analysis['pep8_issues'].append(f"Line {i}: Trailing whitespace")
            
            if '  ' in line and not line.strip().startswith('#'):
                analysis['pep8_issues'].append(f"Line {i}: Multiple spaces")
    
    def _analyze_solid(self, tree, analysis):
        """–ê–Ω–∞–ª–∏–∑ SOLID –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤"""
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                # Single Responsibility Principle
                methods = [n for n in node.body if isinstance(n, ast.FunctionDef)]
                if len(methods) > 10:
                    analysis['solid_issues'].append(f"Class {node.name}: Too many methods ({len(methods)}) - SRP violation")
                
                # Interface Segregation Principle
                abstract_methods = [n for n in methods if any(isinstance(d, ast.Name) and d.id == 'abstractmethod' for d in n.decorator_list)]
                if len(abstract_methods) > 5:
                    analysis['solid_issues'].append(f"Class {node.name}: Too many abstract methods ({len(abstract_methods)}) - ISP violation")
            
            elif isinstance(node, ast.FunctionDef):
                # Open/Closed Principle - –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∂–µ—Å—Ç–∫–æ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                for child in ast.walk(node):
                    if isinstance(child, ast.Constant) and isinstance(child.value, str):
                        if len(child.value) > 50 and not child.value.startswith('http'):
                            analysis['solid_issues'].append(f"Function {node.name}: Hardcoded string - OCP violation")
    
    def _analyze_dry(self, content, analysis):
        """–ê–Ω–∞–ª–∏–∑ DRY –ø—Ä–∏–Ω—Ü–∏–ø–∞"""
        lines = content.split('\n')
        
        # –ü–æ–∏—Å–∫ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞
        code_blocks = {}
        for i, line in enumerate(lines):
            if line.strip() and not line.strip().startswith('#'):
                if line in code_blocks:
                    code_blocks[line].append(i + 1)
                else:
                    code_blocks[line] = [i + 1]
        
        for line, occurrences in code_blocks.items():
            if len(occurrences) > 3:
                analysis['dry_issues'].append(f"Duplicate code block: '{line[:50]}...' appears {len(occurrences)} times at lines {occurrences}")
    
    def _analyze_security(self, content, analysis):
        """–ê–Ω–∞–ª–∏–∑ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
        security_patterns = {
            'sql_injection': [r'execute\s*\(\s*["\'].*%.*["\']', r'cursor\.execute\s*\(\s*f["\']'],
            'xss': [r'innerHTML\s*=', r'document\.write\s*\('],
            'unsafe_eval': [r'eval\s*\(', r'exec\s*\('],
            'hardcoded_secrets': [r'password\s*=\s*["\'][^"\']+["\']', r'secret\s*=\s*["\'][^"\']+["\']'],
            'weak_crypto': [r'md5\s*\(', r'sha1\s*\('],
            'path_traversal': [r'open\s*\(\s*[^)]*\+', r'file\s*\(\s*[^)]*\+']
        }
        
        for pattern_name, patterns in security_patterns.items():
            for pattern in patterns:
                matches = re.finditer(pattern, content, re.IGNORECASE)
                for match in matches:
                    line_num = content[:match.start()].count('\n') + 1
                    analysis['security_issues'].append(f"Line {line_num}: Potential {pattern_name} vulnerability")
    
    def _analyze_architecture(self, tree, analysis):
        """–ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"""
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ God Class
                methods = [n for n in node.body if isinstance(n, ast.FunctionDef)]
                if len(methods) > 15:
                    analysis['architecture_issues'].append(f"Class {node.name}: God Class detected ({len(methods)} methods)")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ Feature Envy
                for method in methods:
                    external_calls = 0
                    for child in ast.walk(method):
                        if isinstance(child, ast.Call) and isinstance(child.func, ast.Attribute):
                            if not child.func.value.id == 'self':
                                external_calls += 1
                    
                    if external_calls > 5:
                        analysis['architecture_issues'].append(f"Method {method.name}: Feature Envy detected ({external_calls} external calls)")
    
    def _analyze_docstrings(self, tree, analysis):
        """–ê–Ω–∞–ª–∏–∑ docstrings"""
        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.ClassDef)):
                if not ast.get_docstring(node):
                    analysis['docstring_issues'].append(f"{type(node).__name__} {node.name}: Missing docstring")
                else:
                    docstring = ast.get_docstring(node)
                    if len(docstring) < 20:
                        analysis['docstring_issues'].append(f"{type(node).__name__} {node.name}: Docstring too short")
    
    def _analyze_complexity(self, tree, analysis):
        """–ê–Ω–∞–ª–∏–∑ —Ü–∏–∫–ª–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏"""
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                complexity = 1  # –ë–∞–∑–æ–≤–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
                
                for child in ast.walk(node):
                    if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor, ast.ExceptHandler)):
                        complexity += 1
                    elif isinstance(child, ast.BoolOp):
                        complexity += len(child.values) - 1
                
                if complexity > 10:
                    analysis['complexity_issues'].append(f"Function {node.name}: High cyclomatic complexity ({complexity})")
    
    def _analyze_readability(self, content, analysis):
        """–ê–Ω–∞–ª–∏–∑ —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏"""
        lines = content.split('\n')
        
        for i, line in enumerate(lines, 1):
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –∏–º–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
            words = re.findall(r'\b[a-zA-Z_][a-zA-Z0-9_]*\b', line)
            for word in words:
                if len(word) > 30:
                    analysis['readability_issues'].append(f"Line {i}: Variable name too long: {word}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏–º–µ–Ω–∞
            for word in words:
                if len(word) == 1 and word.isalpha() and word not in ['i', 'j', 'k', 'x', 'y', 'z']:
                    analysis['readability_issues'].append(f"Line {i}: Variable name too short: {word}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º–∞–≥–∏—á–µ—Å–∫–∏–µ —á–∏—Å–ª–∞
            numbers = re.findall(r'\b\d+\b', line)
            for num in numbers:
                if int(num) > 100 and not line.strip().startswith('#'):
                    analysis['readability_issues'].append(f"Line {i}: Magic number: {num}")
    
    def _calculate_score(self, analysis):
        """–ü–æ–¥—Å—á–µ—Ç –æ–±—â–µ–≥–æ –±–∞–ª–ª–∞ –∫–∞—á–µ—Å—Ç–≤–∞"""
        total_issues = (
            len(analysis['pep8_issues']) +
            len(analysis['solid_issues']) +
            len(analysis['dry_issues']) +
            len(analysis['security_issues']) +
            len(analysis['architecture_issues']) +
            len(analysis['docstring_issues']) +
            len(analysis['complexity_issues']) +
            len(analysis['readability_issues'])
        )
        
        # –ë–∞–∑–æ–≤—ã–π –±–∞–ª–ª 100, –≤—ã—á–∏—Ç–∞–µ–º –∑–∞ –∫–∞–∂–¥—É—é –ø—Ä–æ–±–ª–µ–º—É
        analysis['score'] = max(0, 100 - total_issues * 2)
    
    def analyze_all_functions(self):
        """–ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —Ñ—É–Ω–∫—Ü–∏–π –≤ —Å–∏—Å—Ç–µ–º–µ"""
        print("üîç –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –ê–ù–ê–õ–ò–ó –ö–ê–ß–ï–°–¢–í–ê –ö–û–î–ê")
        print("=" * 80)
        print(f"üìÖ –í—Ä–µ–º—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print()
        
        # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        files_to_analyze = [
            # Core —Ñ–∞–π–ª—ã
            "core/base.py",
            "core/service_base.py",
            "core/database.py",
            "core/configuration.py",
            "core/logging_module.py",
            "core/security_base.py",
            
            # Security –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã
            "security/safe_function_manager.py",
            "security/security_monitoring.py",
            "security/authentication.py",
            "security/access_control.py",
            "security/security_policy.py",
            "security/security_reporting.py",
            
            # Family —Ñ—É–Ω–∫—Ü–∏–∏
            "security/family/family_profile_manager.py",
            "security/family/child_protection.py",
            "security/family/elderly_protection.py",
            
            # Preliminary —Ñ—É–Ω–∫—Ü–∏–∏
            "security/preliminary/policy_engine.py",
            "security/preliminary/risk_assessment.py",
            "security/preliminary/behavioral_analysis.py",
            "security/preliminary/mfa_service.py",
            "security/preliminary/zero_trust_service.py",
            "security/preliminary/trust_scoring.py",
            "security/preliminary/context_aware_access.py",
            
            # Reactive —Ñ—É–Ω–∫—Ü–∏–∏
            "security/reactive/recovery_service.py",
            "security/reactive/threat_intelligence.py",
            "security/reactive/forensics_service.py",
            
            # Microservices
            "security/microservices/api_gateway.py",
            "security/microservices/load_balancer.py",
            "security/microservices/rate_limiter.py",
            "security/microservices/circuit_breaker.py",
            "security/microservices/user_interface_manager.py",
            "security/microservices/redis_cache_manager.py",
            "security/microservices/service_mesh_manager.py",
            
            # AI Agents
            "security/managers/monitor_manager.py",
            "security/managers/alert_manager.py",
            "security/managers/report_manager.py",
            "security/managers/analytics_manager.py",
            "security/managers/dashboard_manager.py",
            "security/ai_agents/data_protection_agent.py",
            "security/ai_agents/mobile_security_agent.py",
            
            # Bots
            "security/bots/mobile_navigation_bot.py",
            "security/bots/gaming_security_bot.py",
            "security/bots/emergency_response_bot.py",
            "security/bots/parental_control_bot.py",
            "security/bots/notification_bot.py",
            "security/bots/whatsapp_security_bot.py",
            "security/bots/telegram_security_bot.py",
            "security/bots/instagram_security_bot.py",
            "security/bots/analytics_bot.py",
            "security/bots/website_navigation_bot.py",
            "security/bots/browser_security_bot.py",
            "security/bots/cloud_storage_security_bot.py",
            "security/bots/network_security_bot.py",
            "security/bots/device_security_bot.py",
            
            # Privacy
            "security/privacy/universal_privacy_manager.py",
            
            # Compliance
            "security/compliance/russian_child_protection_manager.py",
            "security/compliance/russian_data_protection_manager.py",
            
            # CI/CD
            "security/ci_cd/ci_pipeline_manager.py",
            
            # Scaling
            "security/scaling/auto_scaling_engine.py",
            
            # Orchestration
            "security/orchestration/kubernetes_orchestrator.py"
        ]
        
        total_files = len(files_to_analyze)
        analyzed_files = 0
        total_score = 0
        
        print(f"üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {total_files} —Ñ–∞–π–ª–æ–≤...")
        print()
        
        for file_path in files_to_analyze:
            full_path = os.path.join(self.base_path, file_path)
            if os.path.exists(full_path):
                print(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º: {file_path}")
                analysis = self.analyze_file(full_path)
                self.function_analysis[file_path] = analysis
                
                if 'error' not in analysis:
                    total_score += analysis['score']
                    analyzed_files += 1
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
                    if analysis['score'] < 80:
                        print(f"   ‚ö†Ô∏è  –ö–∞—á–µ—Å—Ç–≤–æ: {analysis['score']}/100")
                        if analysis['pep8_issues']:
                            print(f"   üìù PEP8: {len(analysis['pep8_issues'])} –ø—Ä–æ–±–ª–µ–º")
                        if analysis['security_issues']:
                            print(f"   üîí –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: {len(analysis['security_issues'])} –ø—Ä–æ–±–ª–µ–º")
                        if analysis['solid_issues']:
                            print(f"   üèóÔ∏è  SOLID: {len(analysis['solid_issues'])} –ø—Ä–æ–±–ª–µ–º")
                    else:
                        print(f"   ‚úÖ –ö–∞—á–µ—Å—Ç–≤–æ: {analysis['score']}/100")
                else:
                    print(f"   ‚ùå –û—à–∏–±–∫–∞: {analysis['error']}")
            else:
                print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        
        print()
        print("üìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ö–ê–ß–ï–°–¢–í–ê:")
        print("-" * 80)
        
        if analyzed_files > 0:
            average_score = total_score / analyzed_files
            print(f"üìà –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –∫–∞—á–µ—Å—Ç–≤–∞: {average_score:.1f}/100")
            print(f"üìÅ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {analyzed_files}/{total_files}")
            
            # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
            excellent = len([f for f in self.function_analysis.values() if f.get('score', 0) >= 90])
            good = len([f for f in self.function_analysis.values() if 80 <= f.get('score', 0) < 90])
            fair = len([f for f in self.function_analysis.values() if 70 <= f.get('score', 0) < 80])
            poor = len([f for f in self.function_analysis.values() if f.get('score', 0) < 70])
            
            print(f"üèÜ –û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ (90-100): {excellent} —Ñ–∞–π–ª–æ–≤")
            print(f"‚úÖ –•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ (80-89): {good} —Ñ–∞–π–ª–æ–≤")
            print(f"‚ö†Ô∏è  –£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ (70-79): {fair} —Ñ–∞–π–ª–æ–≤")
            print(f"‚ùå –¢—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è (<70): {poor} —Ñ–∞–π–ª–æ–≤")
            
            # –¢–æ–ø –ø—Ä–æ–±–ª–µ–º
            self._show_top_issues()
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            self._show_recommendations(average_score)
        
        print()
        print("=" * 80)
        print("‚úÖ –ê–ù–ê–õ–ò–ó –ö–ê–ß–ï–°–¢–í–ê –ó–ê–í–ï–†–®–ï–ù!")
        print("=" * 80)
    
    def _show_top_issues(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ø –ø—Ä–æ–±–ª–µ–º"""
        print()
        print("üîç –¢–û–ü –ü–†–û–ë–õ–ï–ú –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
        print("-" * 80)
        
        issue_counts = {
            'PEP8': 0,
            'SOLID': 0,
            'DRY': 0,
            '–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': 0,
            '–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞': 0,
            'Docstrings': 0,
            '–°–ª–æ–∂–Ω–æ—Å—Ç—å': 0,
            '–ß–∏—Ç–∞–µ–º–æ—Å—Ç—å': 0
        }
        
        for analysis in self.function_analysis.values():
            if 'error' not in analysis:
                issue_counts['PEP8'] += len(analysis['pep8_issues'])
                issue_counts['SOLID'] += len(analysis['solid_issues'])
                issue_counts['DRY'] += len(analysis['dry_issues'])
                issue_counts['–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å'] += len(analysis['security_issues'])
                issue_counts['–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞'] += len(analysis['architecture_issues'])
                issue_counts['Docstrings'] += len(analysis['docstring_issues'])
                issue_counts['–°–ª–æ–∂–Ω–æ—Å—Ç—å'] += len(analysis['complexity_issues'])
                issue_counts['–ß–∏—Ç–∞–µ–º–æ—Å—Ç—å'] += len(analysis['readability_issues'])
        
        sorted_issues = sorted(issue_counts.items(), key=lambda x: x[1], reverse=True)
        
        for category, count in sorted_issues:
            if count > 0:
                print(f"   {category:15} | {count:3d} –ø—Ä–æ–±–ª–µ–º")
    
    def _show_recommendations(self, average_score):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        print()
        print("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –£–õ–£–ß–®–ï–ù–ò–Æ:")
        print("-" * 80)
        
        if average_score < 70:
            print("üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–û–ë–õ–ï–ú–´:")
            print("   1. –ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
            print("   2. –î–æ–±–∞–≤–∏—Ç—å docstrings –¥–ª—è –≤—Å–µ—Ö —Ñ—É–Ω–∫—Ü–∏–π –∏ –∫–ª–∞—Å—Å–æ–≤")
            print("   3. –ò—Å–ø—Ä–∞–≤–∏—Ç—å PEP8 –Ω–∞—Ä—É—à–µ–Ω–∏—è")
            print("   4. –†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ —Å–ª–æ–∂–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π")
        elif average_score < 80:
            print("‚ö†Ô∏è  –°–†–ï–î–ù–ò–ï –ü–†–û–ë–õ–ï–ú–´:")
            print("   1. –£–ª—É—á—à–∏—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Å–æ–≥–ª–∞—Å–Ω–æ SOLID –ø—Ä–∏–Ω—Ü–∏–ø–∞–º")
            print("   2. –£—Å—Ç—Ä–∞–Ω–∏—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞ (DRY)")
            print("   3. –î–æ–±–∞–≤–∏—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ docstrings")
            print("   4. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —á–∏—Ç–∞–µ–º–æ—Å—Ç—å –∫–æ–¥–∞")
        elif average_score < 90:
            print("‚úÖ –•–û–†–û–®–ï–ï –ö–ê–ß–ï–°–¢–í–û:")
            print("   1. –ú–µ–ª–∫–∏–µ —É–ª—É—á—à–µ–Ω–∏—è PEP8")
            print("   2. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ docstrings")
            print("   3. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
        else:
            print("üèÜ –û–¢–õ–ò–ß–ù–û–ï –ö–ê–ß–ï–°–¢–í–û!")
            print("   1. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å —Ç–µ–∫—É—â–∏–π —É—Ä–æ–≤–µ–Ω—å")
            print("   2. –†–µ–≥—É–ª—è—Ä–Ω—ã–µ code reviews")
            print("   3. –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ")

if __name__ == "__main__":
    analyzer = CodeQualityAnalyzer()
    analyzer.analyze_all_functions()