#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø—É—Ç–µ–π –≤ SFM —Ä–µ–µ—Å—Ç—Ä–µ
–í—ã—è—Å–Ω—è–µ—Ç, –ø–æ—á–µ–º—É –±—ã–ª–∏ —Å–æ–∑–¥–∞–Ω—ã –∏–º–µ–Ω–Ω–æ —Ç–∞–∫–∏–µ –ø—É—Ç–∏
"""

import json
import os
from pathlib import Path
from typing import Dict, List, Tuple
from datetime import datetime

def load_sfm_registry() -> Dict:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç SFM —Ä–µ–µ—Å—Ç—Ä –∏–∑ JSON —Ñ–∞–π–ª–∞"""
    registry_path = Path("data/sfm/function_registry.json")
    
    if not registry_path.exists():
        print(f"‚ùå –§–∞–π–ª —Ä–µ–µ—Å—Ç—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {registry_path}")
        return {}
    
    try:
        with open(registry_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data.get('functions', {})
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–µ—Å—Ç—Ä–∞: {e}")
        return {}

def analyze_path_patterns():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø—É—Ç–µ–π –≤ SFM —Ä–µ–µ—Å—Ç—Ä–µ"""
    print("üîç –ê–ù–ê–õ–ò–ó –ü–ê–¢–¢–ï–†–ù–û–í –ü–£–¢–ï–ô –í SFM –†–ï–ï–°–¢–†–ï")
    print("=" * 70)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–µ—Å—Ç—Ä
    functions = load_sfm_registry()
    if not functions:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å SFM —Ä–µ–µ—Å—Ç—Ä")
        return
    
    base_dir = Path.cwd()
    print(f"üìÅ –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {base_dir}")
    print(f"üìä –í—Å–µ–≥–æ —Ñ—É–Ω–∫—Ü–∏–π –≤ —Ä–µ–µ—Å—Ç—Ä–µ: {len(functions)}")
    print()
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    path_patterns = {
        'underscore_vs_camelcase': {'underscore': 0, 'camelcase': 0, 'mixed': 0},
        'directory_structure': {},
        'naming_conventions': {},
        'file_extensions': {},
        'creation_dates': {},
        'function_types': {}
    }
    
    existing_files = []
    missing_files = []
    path_analysis = []
    
    for func_id, func_data in functions.items():
        file_path_str = func_data.get('file_path', '')
        if not file_path_str:
            continue
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—É—Ç—å
        if file_path_str.startswith('./'):
            file_path_str = file_path_str[2:]
        
        normalized_path = base_dir / file_path_str
        file_exists = normalized_path.exists() and normalized_path.is_file()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        file_name = Path(file_path_str).name
        file_stem = Path(file_path_str).stem
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∏–ª—å –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è
        if '_' in file_stem:
            path_patterns['underscore_vs_camelcase']['underscore'] += 1
            naming_style = 'underscore'
        elif any(c.isupper() for c in file_stem[1:]):
            path_patterns['underscore_vs_camelcase']['camelcase'] += 1
            naming_style = 'camelcase'
        else:
            path_patterns['underscore_vs_camelcase']['mixed'] += 1
            naming_style = 'mixed'
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        dir_path = str(Path(file_path_str).parent)
        if dir_path not in path_patterns['directory_structure']:
            path_patterns['directory_structure'][dir_path] = 0
        path_patterns['directory_structure'][dir_path] += 1
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–∏–ø—ã —Ñ—É–Ω–∫—Ü–∏–π
        func_type = func_data.get('function_type', 'unknown')
        if func_type not in path_patterns['function_types']:
            path_patterns['function_types'][func_type] = {'total': 0, 'existing': 0, 'missing': 0}
        path_patterns['function_types'][func_type]['total'] += 1
        
        if file_exists:
            path_patterns['function_types'][func_type]['existing'] += 1
            existing_files.append(func_id)
        else:
            path_patterns['function_types'][func_type]['missing'] += 1
            missing_files.append(func_id)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞—Ç—ã —Å–æ–∑–¥–∞–Ω–∏—è
        created_at = func_data.get('created_at', '')
        if created_at:
            date_part = created_at[:10]  # YYYY-MM-DD
            if date_part not in path_patterns['creation_dates']:
                path_patterns['creation_dates'][date_part] = 0
            path_patterns['creation_dates'][date_part] += 1
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è
        path_analysis.append({
            'function_id': func_id,
            'file_path': file_path_str,
            'file_name': file_name,
            'file_stem': file_stem,
            'naming_style': naming_style,
            'directory': dir_path,
            'function_type': func_type,
            'exists': file_exists,
            'created_at': created_at,
            'status': func_data.get('status', 'unknown')
        })
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
    print("üìä –ê–ù–ê–õ–ò–ó –ü–ê–¢–¢–ï–†–ù–û–í –ò–ú–ï–ù–û–í–ê–ù–ò–Ø:")
    print("-" * 70)
    
    naming_stats = path_patterns['underscore_vs_camelcase']
    total_naming = sum(naming_stats.values())
    
    print(f"üìù –°—Ç–∏–ª–∏ –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤:")
    print(f"   –ü–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è (_): {naming_stats['underscore']:3d} ({naming_stats['underscore']/total_naming*100:.1f}%)")
    print(f"   CamelCase:         {naming_stats['camelcase']:3d} ({naming_stats['camelcase']/total_naming*100:.1f}%)")
    print(f"   –°–º–µ—à–∞–Ω–Ω—ã–π:         {naming_stats['mixed']:3d} ({naming_stats['mixed']/total_naming*100:.1f}%)")
    
    print(f"\nüìÇ –°–¢–†–£–ö–¢–£–†–ê –î–ò–†–ï–ö–¢–û–†–ò–ô:")
    print("-" * 70)
    
    sorted_dirs = sorted(path_patterns['directory_structure'].items(), key=lambda x: x[1], reverse=True)
    for dir_path, count in sorted_dirs[:15]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-15
        print(f"   {dir_path:30} | {count:3d} —Ñ–∞–π–ª–æ–≤")
    
    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –¢–ò–ü–ê–ú –§–£–ù–ö–¶–ò–ô:")
    print("-" * 70)
    
    for func_type, stats in sorted(path_patterns['function_types'].items()):
        existing_pct = (stats['existing'] / stats['total'] * 100) if stats['total'] > 0 else 0
        print(f"   {func_type:20} | –í—Å–µ–≥–æ: {stats['total']:3d} | –°—É—â–µ—Å—Ç–≤—É—é—Ç: {stats['existing']:3d} ({existing_pct:5.1f}%)")
    
    print(f"\nüìÖ –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –î–ê–¢–ê–ú –°–û–ó–î–ê–ù–ò–Ø:")
    print("-" * 70)
    
    sorted_dates = sorted(path_patterns['creation_dates'].items(), reverse=True)
    for date, count in sorted_dates[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 –¥–∞—Ç
        print(f"   {date} | {count:3d} —Ñ—É–Ω–∫—Ü–∏–π")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    print(f"\nüîç –ê–ù–ê–õ–ò–ó –ü–†–û–ë–õ–ï–ú–ù–´–• –ü–ê–¢–¢–ï–†–ù–û–í:")
    print("-" * 70)
    
    # –ò—â–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ —Å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø—É—Ç—è–º–∏
    problematic_patterns = {
        'missing_underscores': [],
        'wrong_directories': [],
        'camelcase_files': [],
        'old_paths': []
    }
    
    for analysis in path_analysis:
        if not analysis['exists']:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º, –ø–æ—á–µ–º—É —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
            if analysis['naming_style'] == 'camelcase':
                problematic_patterns['camelcase_files'].append(analysis)
            elif 'security' in analysis['directory'] and analysis['function_type'] in ['ai_agent', 'bot', 'manager']:
                # –í–æ–∑–º–æ–∂–Ω–æ, —Ñ–∞–π–ª –≤ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
                expected_dirs = {
                    'ai_agent': 'security/ai_agents',
                    'bot': 'security/bots',
                    'manager': 'security/managers'
                }
                expected_dir = expected_dirs.get(analysis['function_type'])
                if expected_dir and expected_dir not in analysis['directory']:
                    problematic_patterns['wrong_directories'].append(analysis)
    
    print(f"‚ùå –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã:")
    print(f"   CamelCase —Ñ–∞–π–ª—ã: {len(problematic_patterns['camelcase_files'])}")
    print(f"   –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {len(problematic_patterns['wrong_directories'])}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    if problematic_patterns['camelcase_files']:
        print(f"\nüî∏ –ü–†–ò–ú–ï–†–´ CAMELCASE –§–ê–ô–õ–û–í:")
        for analysis in problematic_patterns['camelcase_files'][:5]:
            print(f"   {analysis['function_id']} ‚Üí {analysis['file_path']}")
    
    if problematic_patterns['wrong_directories']:
        print(f"\nüî∏ –ü–†–ò–ú–ï–†–´ –ù–ï–ü–†–ê–í–ò–õ–¨–ù–´–• –î–ò–†–ï–ö–¢–û–†–ò–ô:")
        for analysis in problematic_patterns['wrong_directories'][:5]:
            print(f"   {analysis['function_id']} ‚Üí {analysis['file_path']} (—Ç–∏–ø: {analysis['function_type']})")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —ç–≤–æ–ª—é—Ü–∏—é —Å–∏—Å—Ç–µ–º—ã
    print(f"\nüìà –≠–í–û–õ–Æ–¶–ò–Ø –°–ò–°–¢–ï–ú–´:")
    print("-" * 70)
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø–µ—Ä–∏–æ–¥–∞–º —Å–æ–∑–¥–∞–Ω–∏—è
    periods = {
        '2025-09-01 - 2025-09-10': 0,
        '2025-09-11 - 2025-09-20': 0,
        '2025-09-21 - 2025-09-30': 0,
        '2025-10-01 - 2025-10-10': 0
    }
    
    for date_str, count in path_patterns['creation_dates'].items():
        if '2025-09-01' <= date_str <= '2025-09-10':
            periods['2025-09-01 - 2025-09-10'] += count
        elif '2025-09-11' <= date_str <= '2025-09-20':
            periods['2025-09-11 - 2025-09-20'] += count
        elif '2025-09-21' <= date_str <= '2025-09-30':
            periods['2025-09-21 - 2025-09-30'] += count
        elif '2025-10-01' <= date_str <= '2025-10-10':
            periods['2025-10-01 - 2025-10-10'] += count
    
    for period, count in periods.items():
        print(f"   {period} | {count:3d} —Ñ—É–Ω–∫—Ü–∏–π")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    analysis_report = {
        'timestamp': datetime.now().isoformat(),
        'total_functions': len(functions),
        'existing_files': len(existing_files),
        'missing_files': len(missing_files),
        'path_patterns': path_patterns,
        'path_analysis': path_analysis,
        'problematic_patterns': {
            key: [{'function_id': item['function_id'], 'file_path': item['file_path']} 
                  for item in items] 
            for key, items in problematic_patterns.items()
        }
    }
    
    report_path = f"data/reports/path_patterns_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    os.makedirs(os.path.dirname(report_path), exist_ok=True)
    
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(analysis_report, f, ensure_ascii=False, indent=2)
    
    print(f"\nüìÑ –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
    
    return analysis_report

if __name__ == "__main__":
    try:
        analysis_report = analyze_path_patterns()
        print(f"\nüéØ –ê–ù–ê–õ–ò–ó –ü–ê–¢–¢–ï–†–ù–û–í –ó–ê–í–ï–†–®–ï–ù")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()