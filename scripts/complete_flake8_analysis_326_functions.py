#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ flake8 –¥–ª—è –≤—Å–µ—Ö 326 —Ñ—É–Ω–∫—Ü–∏–π SFM —Å–∏—Å—Ç–µ–º—ã
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–±–∞–∑–æ–≤—ã–π flake8 –±–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
"""

import os
import subprocess
import json
from pathlib import Path
from collections import defaultdict
from datetime import datetime

def run_flake8_standard(file_path):
    """–ó–∞–ø—É—Å–∫ flake8 —Å –±–∞–∑–æ–≤—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ (–∫–∞–∫ –≤ pyproject.toml)"""
    try:
        result = subprocess.run([
            'python3', '-m', 'flake8', 
            file_path,
            '--statistics'
        ], capture_output=True, text=True, timeout=60)
        
        return result.returncode, result.stdout, result.stderr
    except Exception as e:
        return -1, "", str(e)

def analyze_errors(output):
    """–ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ flake8"""
    errors = defaultdict(int)
    total_errors = 0
    
    lines = output.strip().split('\n')
    for line in lines:
        if ':' in line and not line.startswith('['):
            parts = line.split(':')
            if len(parts) >= 4:
                error_code = parts[3].strip().split()[0]
                errors[error_code] += 1
                total_errors += 1
    
    return total_errors, dict(errors)

def get_all_python_files(directory):
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ Python —Ñ–∞–π–ª—ã –≤ –ø—Ä–æ–µ–∫—Ç–µ"""
    python_files = []
    exclude_dirs = {
        'ALADDIN_BACKUP', 'ALADDIN_NEW_BACKUP', 'ALADDIN_SECURITY_FULL_BACKUP',
        'backup', 'test', '__pycache__', '.git', '.venv', 'venv'
    }
    
    for root, dirs, files in os.walk(directory):
        # –ò—Å–∫–ª—é—á–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        dirs[:] = [d for d in dirs if not any(exclude in d for exclude in exclude_dirs)]
        
        for file in files:
            if file.endswith('.py') and not any(exclude in file for exclude in exclude_dirs):
                python_files.append(Path(root) / file)
    
    return python_files

def categorize_file(file_path):
    """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ñ–∞–π–ª–∞"""
    path_str = str(file_path)
    
    if 'core/' in path_str:
        return 'core'
    elif 'security/safe_function_manager.py' in path_str:
        return 'security_sfm'
    elif 'security/ai_agents/' in path_str:
        return 'ai_agent'
    elif 'security/bots/' in path_str:
        return 'bot'
    elif 'security/microservices/' in path_str:
        return 'microservice'
    elif 'security/' in path_str:
        return 'security'
    elif 'config/' in path_str:
        return 'config'
    elif 'tests/' in path_str:
        return 'test'
    elif 'scripts/' in path_str:
        return 'script'
    else:
        return 'other'

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üîç –ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó FLAKE8 –î–õ–Ø –í–°–ï–• 326 –§–£–ù–ö–¶–ò–ô SFM –°–ò–°–¢–ï–ú–´")
    print("=" * 70)
    print("–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏: –±–∞–∑–æ–≤—ã–π flake8 (pyproject.toml)")
    print("=" * 70)
    
    project_root = Path(os.getcwd())
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ Python —Ñ–∞–π–ª—ã
    all_python_files = get_all_python_files(project_root)
    print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(all_python_files)} Python —Ñ–∞–π–ª–æ–≤")
    
    results = {
        'total_files': len(all_python_files),
        'clean_files': 0,
        'files_with_errors': 0,
        'total_errors': 0,
        'error_types': defaultdict(int),
        'category_stats': defaultdict(lambda: {
            'total': 0,
            'clean': 0,
            'errors': 0,
            'total_error_count': 0
        }),
        'file_details': [],
        'critical_files': [],
        'analysis_time': datetime.now().isoformat()
    }
    
    print(f"\nüîç –ê–ù–ê–õ–ò–ó {len(all_python_files)} –§–ê–ô–õ–û–í:")
    print("-" * 70)
    
    for i, filepath in enumerate(all_python_files, 1):
        relative_path = filepath.relative_to(project_root)
        category = categorize_file(filepath)
        
        print(f"[{i:3d}/{len(all_python_files)}] {relative_path}")
        
        # –ó–∞–ø—É—Å–∫ flake8
        returncode, stdout, stderr = run_flake8_standard(filepath)
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if returncode == 0:
            total_errors = 0
            errors = {}
            status = "‚úÖ –ß–ò–°–¢–´–ô"
            results['clean_files'] += 1
            results['category_stats'][category]['clean'] += 1
        else:
            total_errors, errors = analyze_errors(stdout)
            if total_errors == 0:
                status = "‚úÖ –ß–ò–°–¢–´–ô"
                results['clean_files'] += 1
                results['category_stats'][category]['clean'] += 1
            else:
                status = f"‚ùå {total_errors} –æ—à–∏–±–æ–∫"
                results['files_with_errors'] += 1
                results['category_stats'][category]['errors'] += 1
                results['category_stats'][category]['total_error_count'] += total_errors
                
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã –µ—Å–ª–∏ –º–Ω–æ–≥–æ –æ—à–∏–±–æ–∫
                if total_errors > 50:
                    results['critical_files'].append({
                        'file': str(relative_path),
                        'category': category,
                        'errors': total_errors,
                        'error_types': errors
                    })
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        results['total_errors'] += total_errors
        results['category_stats'][category]['total'] += 1
        
        for error_type, count in errors.items():
            results['error_types'][error_type] += count
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–µ—Ç–∞–ª–µ–π
        file_detail = {
            'file_path': str(relative_path),
            'category': category,
            'is_clean': total_errors == 0,
            'total_errors': total_errors,
            'errors': errors,
            'full_output': stdout if total_errors > 0 else ""
        }
        results['file_details'].append(file_detail)
        
        print(f"     {status} ({category})")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-3 –æ—à–∏–±–∫–∏ –¥–ª—è —Ñ–∞–π–ª–æ–≤ —Å –æ—à–∏–±–∫–∞–º–∏
        if total_errors > 0 and total_errors <= 20:
            for error_type, count in sorted(errors.items(), key=lambda x: x[1], reverse=True)[:3]:
                print(f"       {error_type}: {count}")
        elif total_errors > 20:
            print(f"       –ú–ù–û–ì–û –û–®–ò–ë–û–ö - —Å–º. –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    output_file = 'COMPLETE_FLAKE8_ANALYSIS_326_FUNCTIONS.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º defaultdict –≤ –æ–±—ã—á–Ω—ã–µ dict –¥–ª—è JSON
        json_results = {
            'total_files': results['total_files'],
            'clean_files': results['clean_files'],
            'files_with_errors': results['files_with_errors'],
            'total_errors': results['total_errors'],
            'error_types': dict(results['error_types']),
            'category_stats': dict(results['category_stats']),
            'file_details': results['file_details'],
            'critical_files': results['critical_files'],
            'analysis_time': results['analysis_time']
        }
        json.dump(json_results, f, indent=2, ensure_ascii=False)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞
    report_file = 'COMPLETE_FLAKE8_REPORT_326_FUNCTIONS.md'
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# üîç –ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó FLAKE8 –î–õ–Ø –í–°–ï–• 326 –§–£–ù–ö–¶–ò–ô SFM –°–ò–°–¢–ï–ú–´\n\n")
        f.write(f"**–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞:** {results['analysis_time']}\n")
        f.write(f"**–ê–Ω–∞–ª–∏—Ç–∏–∫:** AI Security Assistant\n")
        f.write(f"**–ù–∞—Å—Ç—Ä–æ–π–∫–∏:** –ë–∞–∑–æ–≤—ã–π flake8 (pyproject.toml)\n\n")
        
        f.write("## üìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê\n\n")
        f.write(f"- **–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤:** {results['total_files']}\n")
        f.write(f"- **–ß–∏—Å—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤:** {results['clean_files']} ({results['clean_files']/results['total_files']*100:.1f}%)\n")
        f.write(f"- **–§–∞–π–ª–æ–≤ —Å –æ—à–∏–±–∫–∞–º–∏:** {results['files_with_errors']} ({results['files_with_errors']/results['total_files']*100:.1f}%)\n")
        f.write(f"- **–í—Å–µ–≥–æ –æ—à–∏–±–æ–∫:** {results['total_errors']}\n\n")
        
        f.write("## üìà –¢–û–ü-10 –û–®–ò–ë–û–ö –ü–û –¢–ò–ü–ê–ú\n\n")
        for i, (error_type, count) in enumerate(sorted(results['error_types'].items(), key=lambda x: x[1], reverse=True)[:10], 1):
            f.write(f"{i:2d}. **{error_type}:** {count} –æ—à–∏–±–æ–∫\n")
        
        f.write("\n## üìÅ –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú\n\n")
        for category, stats in results['category_stats'].items():
            if stats['total'] > 0:
                clean_percent = stats['clean'] / stats['total'] * 100
                f.write(f"- **{category}:** {stats['clean']}/{stats['total']} —á–∏—Å—Ç—ã—Ö ({clean_percent:.1f}%), {stats['total_error_count']} –æ—à–∏–±–æ–∫\n")
        
        f.write("\n## üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –§–ê–ô–õ–´ (–±–æ–ª–µ–µ 50 –æ—à–∏–±–æ–∫)\n\n")
        if results['critical_files']:
            for file_info in results['critical_files']:
                f.write(f"- **{file_info['file']}** ({file_info['category']}): {file_info['errors']} –æ—à–∏–±–æ–∫\n")
        else:
            f.write("–ù–µ—Ç —Ñ–∞–π–ª–æ–≤ —Å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –æ—à–∏–±–æ–∫.\n")
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print(f"\nüìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢:")
    print("=" * 70)
    print(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {results['total_files']}")
    print(f"–ß–∏—Å—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤: {results['clean_files']} ({results['clean_files']/results['total_files']*100:.1f}%)")
    print(f"–§–∞–π–ª–æ–≤ —Å –æ—à–∏–±–∫–∞–º–∏: {results['files_with_errors']} ({results['files_with_errors']/results['total_files']*100:.1f}%)")
    print(f"–í—Å–µ–≥–æ –æ—à–∏–±–æ–∫: {results['total_errors']}")
    
    print(f"\nüìà –¢–û–ü-10 –û–®–ò–ë–û–ö –ü–û –¢–ò–ü–ê–ú:")
    for i, (error_type, count) in enumerate(sorted(results['error_types'].items(), key=lambda x: x[1], reverse=True)[:10], 1):
        print(f"  {i:2d}. {error_type}: {count}")
    
    print(f"\nüìÅ –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
    for category, stats in results['category_stats'].items():
        if stats['total'] > 0:
            clean_percent = stats['clean'] / stats['total'] * 100
            print(f"  {category}: {stats['clean']}/{stats['total']} —á–∏—Å—Ç—ã—Ö ({clean_percent:.1f}%), {stats['total_error_count']} –æ—à–∏–±–æ–∫")
    
    print(f"\nüö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –§–ê–ô–õ–´ (–±–æ–ª–µ–µ 50 –æ—à–∏–±–æ–∫):")
    if results['critical_files']:
        for file_info in results['critical_files']:
            print(f"  {file_info['file']} ({file_info['category']}): {file_info['errors']} –æ—à–∏–±–æ–∫")
    else:
        print("  –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ —Å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –æ—à–∏–±–æ–∫.")
    
    print(f"\nüíæ –î–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Ç—á–µ—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
    print(f"  - JSON: {output_file}")
    print(f"  - Markdown: {report_file}")

if __name__ == "__main__":
    main()