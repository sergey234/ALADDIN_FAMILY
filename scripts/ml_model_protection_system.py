#!/usr/bin/env python3
"""
üõ°Ô∏è –°–ò–°–¢–ï–ú–ê –ó–ê–©–ò–¢–´ ML –ú–û–î–ï–õ–ï–ô –í –°–ü–Ø–©–ï–ú –†–ï–ñ–ò–ú–ï
==============================================

–°–∏—Å—Ç–µ–º–∞ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è ML –º–æ–¥–µ–ª–µ–π
–ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ —Ñ—É–Ω–∫—Ü–∏–π –≤ —Å–ø—è—â–∏–π —Ä–µ–∂–∏–º.

–ê–≤—Ç–æ—Ä: ALADDIN Security System
–î–∞—Ç–∞: 2025-09-15
–í–µ—Ä—Å–∏—è: 1.0.0
"""

import os
import json
import pickle
import asyncio
import logging
from typing import Dict, List, Any, Optional, Union
from datetime import datetime
from pathlib import Path
import numpy as np

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MLModelProtectionSystem:
    """–°–∏—Å—Ç–µ–º–∞ –∑–∞—â–∏—Ç—ã ML –º–æ–¥–µ–ª–µ–π –≤ —Å–ø—è—â–µ–º —Ä–µ–∂–∏–º–µ"""
    
    def __init__(self, backup_dir: str = "data/ml_models_backup"):
        self.backup_dir = Path(backup_dir)
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        self.protected_models = {}
        self.model_metadata = {}
        
    async def protect_ml_models(self, function_name: str, models: Dict[str, Any]) -> bool:
        """
        –ó–∞—â–∏—Ç–∞ ML –º–æ–¥–µ–ª–µ–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–≤–æ–¥–æ–º –≤ —Å–ø—è—â–∏–π —Ä–µ–∂–∏–º
        
        Args:
            function_name: –ò–º—è —Ñ—É–Ω–∫—Ü–∏–∏
            models: –°–ª–æ–≤–∞—Ä—å —Å ML –º–æ–¥–µ–ª—è–º–∏
            
        Returns:
            bool: –£—Å–ø–µ—à–Ω–æ—Å—Ç—å –∑–∞—â–∏—Ç—ã
        """
        try:
            logger.info(f"üõ°Ô∏è –ó–∞—â–∏—Ç–∞ ML –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏: {function_name}")
            
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏
            function_dir = self.backup_dir / function_name
            function_dir.mkdir(exist_ok=True)
            
            protected_models = {}
            metadata = {
                "function_name": function_name,
                "protection_time": datetime.now().isoformat(),
                "models_count": len(models),
                "models_info": {}
            }
            
            for model_name, model in models.items():
                try:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
                    model_path = function_dir / f"{model_name}.pkl"
                    with open(model_path, 'wb') as f:
                        pickle.dump(model, f)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
                    model_metadata = {
                        "model_name": model_name,
                        "model_type": type(model).__name__,
                        "file_path": str(model_path),
                        "size_bytes": model_path.stat().st_size,
                        "has_weights": hasattr(model, 'coef_') or hasattr(model, 'weights_'),
                        "is_fitted": hasattr(model, 'predict') and callable(getattr(model, 'predict'))
                    }
                    
                    metadata["models_info"][model_name] = model_metadata
                    protected_models[model_name] = str(model_path)
                    
                    logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} –∑–∞—â–∏—â–µ–Ω–∞: {model_path}")
                    
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞—â–∏—Ç—ã –º–æ–¥–µ–ª–∏ {model_name}: {e}")
                    return False
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata_path = function_dir / "metadata.json"
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–µ—Å—Ç—Ä –∑–∞—â–∏—â–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
            self.protected_models[function_name] = protected_models
            self.model_metadata[function_name] = metadata
            
            logger.info(f"‚úÖ ML –º–æ–¥–µ–ª–∏ —Ñ—É–Ω–∫—Ü–∏–∏ {function_name} —É—Å–ø–µ—à–Ω–æ –∑–∞—â–∏—â–µ–Ω—ã")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞—â–∏—Ç—ã ML –º–æ–¥–µ–ª–µ–π –¥–ª—è {function_name}: {e}")
            return False
    
    async def restore_ml_models(self, function_name: str) -> Optional[Dict[str, Any]]:
        """
        –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–µ–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–∏ –ø—Ä–æ–±—É–∂–¥–µ–Ω–∏–∏
        
        Args:
            function_name: –ò–º—è —Ñ—É–Ω–∫—Ü–∏–∏
            
        Returns:
            Dict[str, Any]: –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏–ª–∏ None
        """
        try:
            logger.info(f"üîÑ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏: {function_name}")
            
            if function_name not in self.protected_models:
                logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –∑–∞—â–∏—â–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏: {function_name}")
                return None
            
            function_dir = self.backup_dir / function_name
            if not function_dir.exists():
                logger.error(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {function_dir}")
                return None
            
            restored_models = {}
            
            for model_name, model_path in self.protected_models[function_name].items():
                try:
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
                    with open(model_path, 'rb') as f:
                        model = pickle.load(f)
                    
                    restored_models[model_name] = model
                    logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
                    
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ {model_name}: {e}")
                    return None
            
            logger.info(f"‚úÖ ML –º–æ–¥–µ–ª–∏ —Ñ—É–Ω–∫—Ü–∏–∏ {function_name} —É—Å–ø–µ—à–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
            return restored_models
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è ML –º–æ–¥–µ–ª–µ–π –¥–ª—è {function_name}: {e}")
            return None
    
    async def get_protected_models_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–∞—â–∏—â–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö"""
        return {
            "protected_functions": list(self.protected_models.keys()),
            "total_models": sum(len(models) for models in self.protected_models.values()),
            "backup_directory": str(self.backup_dir),
            "metadata": self.model_metadata
        }
    
    async def cleanup_old_models(self, days_old: int = 30) -> int:
        """
        –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –º–æ–¥–µ–ª–µ–π
        
        Args:
            days_old: –í–æ–∑—Ä–∞—Å—Ç –º–æ–¥–µ–ª–µ–π –≤ –¥–Ω—è—Ö
            
        Returns:
            int: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        """
        try:
            logger.info(f"üßπ –û—á–∏—Å—Ç–∫–∞ –º–æ–¥–µ–ª–µ–π —Å—Ç–∞—Ä—à–µ {days_old} –¥–Ω–µ–π")
            
            deleted_count = 0
            cutoff_time = datetime.now().timestamp() - (days_old * 24 * 3600)
            
            for function_dir in self.backup_dir.iterdir():
                if function_dir.is_dir():
                    for model_file in function_dir.glob("*.pkl"):
                        if model_file.stat().st_mtime < cutoff_time:
                            model_file.unlink()
                            deleted_count += 1
                            logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª: {model_file}")
            
            logger.info(f"‚úÖ –û—á–∏—â–µ–Ω–æ {deleted_count} —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤")
            return deleted_count
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –º–æ–¥–µ–ª–µ–π: {e}")
            return 0

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–∏—Å—Ç–µ–º—ã –∑–∞—â–∏—Ç—ã
ml_protection = MLModelProtectionSystem()

async def main():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –∑–∞—â–∏—Ç—ã ML –º–æ–¥–µ–ª–µ–π"""
    print("üõ°Ô∏è –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –°–ò–°–¢–ï–ú–´ –ó–ê–©–ò–¢–´ ML –ú–û–î–ï–õ–ï–ô")
    print("=" * 50)
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
    from sklearn.ensemble import IsolationForest
    from sklearn.preprocessing import StandardScaler
    
    test_models = {
        "anomaly_detector": IsolationForest(contamination=0.1),
        "scaler": StandardScaler()
    }
    
    # –¢–µ—Å—Ç –∑–∞—â–∏—Ç—ã
    success = await ml_protection.protect_ml_models("test_function", test_models)
    print(f"–ó–∞—â–∏—Ç–∞ –º–æ–¥–µ–ª–µ–π: {'‚úÖ –£—Å–ø–µ—à–Ω–æ' if success else '‚ùå –û—à–∏–±–∫–∞'}")
    
    # –¢–µ—Å—Ç –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
    restored = await ml_protection.restore_ml_models("test_function")
    print(f"–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π: {'‚úÖ –£—Å–ø–µ—à–Ω–æ' if restored else '‚ùå –û—à–∏–±–∫–∞'}")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞—â–∏—â–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö
    info = await ml_protection.get_protected_models_info()
    print(f"–ó–∞—â–∏—â–µ–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π: {len(info['protected_functions'])}")
    print(f"–í—Å–µ–≥–æ –º–æ–¥–µ–ª–µ–π: {info['total_models']}")

if __name__ == "__main__":
    asyncio.run(main())