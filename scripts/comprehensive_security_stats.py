#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
COMPREHENSIVE ALADDIN SECURITY STATISTICS
–ü–æ–ª–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ ALADDIN —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π SFM

–ê–≤—Ç–æ—Ä: ALADDIN Security Team
–í–µ—Ä—Å–∏—è: 2.0
–î–∞—Ç–∞: 2025-01-27
"""

import os
import sys
import json
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any

class ComprehensiveSecurityStats:
    def __init__(self, project_root="/Users/sergejhlystov/ALADDIN_NEW"):
        self.project_root = Path(project_root)
        self.security_dir = self.project_root / "security"
        self.scripts_dir = self.project_root / "scripts"
        self.core_dir = self.project_root / "core"
        self.config_dir = self.project_root / "config"
        self.data_dir = self.project_root / "data"
        self.sfm_dir = self.data_dir / "sfm"
        
        # –ò—Å–∫–ª—é—á–∞–µ–º—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        self.exclude_patterns = [
            "*/backup*", "*/test*", "*/tests*", "*/logs*", 
            "*/formatting_work*", "*backup*", "*test*", 
            "*_test.py", "*_backup_*.py", "*.pyc", "__pycache__"
        ]
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        self.security_categories = {
            "ai_agents": {"path": "security/ai_agents/", "name": "ü§ñ AI –ê–≥–µ–Ω—Ç—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"},
            "bots": {"path": "security/bots/", "name": "ü§ñ –ë–æ—Ç—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"},
            "managers": {"path": "security/managers/", "name": "‚öôÔ∏è –ú–µ–Ω–µ–¥–∂–µ—Ä—ã —Å–∏—Å—Ç–µ–º—ã"},
            "vpn": {"path": "security/vpn/", "name": "üîí VPN –°–∏—Å—Ç–µ–º–∞"},
            "family": {"path": "security/family/", "name": "üë®‚Äçüë©‚Äçüëß‚Äçüë¶ –°–µ–º–µ–π–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏"},
            "microservices": {"path": "security/microservices/", "name": "üåê –ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å—ã"},
            "core": {"path": "core/", "name": "‚ö° –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã"},
            "other_security": {"path": "security/", "name": "üìÅ –î—Ä—É–≥–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã"}
        }
        
        # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏
        self.architecture_scores = {
            "architecture": 10,
            "integration": 10,
            "security": 10,
            "russian_compliance": 10,
            "production_ready": 10
        }

    def validate_sfm_registry(self) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è SFM —Ä–µ–µ—Å—Ç—Ä–∞ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º"""
        validation_result = {
            "is_valid": False,
            "total_functions": 0,
            "active_functions": 0,
            "sleeping_functions": 0,
            "disabled_functions": 0,
            "categories": {},
            "errors": [],
            "warnings": [],
            "file_info": {},
            "json_structure": {},
            "data_quality": {},
            "validation_details": {}
        }
        
        try:
            registry_file = self.sfm_dir / "function_registry.json"
            if not registry_file.exists():
                validation_result["errors"].append("–§–∞–π–ª —Ä–µ–µ—Å—Ç—Ä–∞ SFM –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return validation_result
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–µ
            file_stat = registry_file.stat()
            validation_result["file_info"] = {
                "file_path": str(registry_file),
                "file_size_bytes": file_stat.st_size,
                "file_size_kb": round(file_stat.st_size / 1024, 2),
                "file_size_mb": round(file_stat.st_size / (1024 * 1024), 2),
                "last_modified": datetime.fromtimestamp(file_stat.st_mtime).strftime("%Y-%m-%d %H:%M:%S"),
                "file_exists": True
            }
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥ JSON
            with open(registry_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã JSON
            validation_result["json_structure"] = {
                "has_functions_key": "functions" in data,
                "top_level_keys": list(data.keys()),
                "is_valid_json": True,
                "encoding": "utf-8"
            }
            
            if "functions" not in data:
                validation_result["errors"].append("–ù–µ–≤–µ—Ä–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ JSON - –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á 'functions'")
                return validation_result
            
            functions = data["functions"]
            validation_result["total_functions"] = len(functions)
            validation_result["is_valid"] = True
            
            # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ñ—É–Ω–∫—Ü–∏–π
            function_analysis = {
                "valid_functions": 0,
                "invalid_functions": 0,
                "missing_fields": {},
                "status_distribution": {},
                "type_distribution": {},
                "security_levels": {},
                "critical_functions": 0,
                "auto_enable_functions": 0,
                "emergency_wake_functions": 0
            }
            
            # –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
            for func_id, func_data in functions.items():
                if not isinstance(func_data, dict):
                    validation_result["warnings"].append(f"–§—É–Ω–∫—Ü–∏—è {func_id} –∏–º–µ–µ—Ç –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö")
                    function_analysis["invalid_functions"] += 1
                    continue
                
                function_analysis["valid_functions"] += 1
                
                # –°—Ç–∞—Ç—É—Å —Ñ—É–Ω–∫—Ü–∏–∏
                status = func_data.get('status', 'unknown')
                if status not in function_analysis["status_distribution"]:
                    function_analysis["status_distribution"][status] = 0
                function_analysis["status_distribution"][status] += 1
                
                if status == 'active':
                    validation_result["active_functions"] += 1
                elif status == 'sleeping':
                    validation_result["sleeping_functions"] += 1
                elif status == 'disabled':
                    validation_result["disabled_functions"] += 1
                
                # –¢–∏–ø —Ñ—É–Ω–∫—Ü–∏–∏
                func_type = func_data.get('function_type', 'UNKNOWN').upper()
                if func_type not in function_analysis["type_distribution"]:
                    function_analysis["type_distribution"][func_type] = 0
                function_analysis["type_distribution"][func_type] += 1
                
                # –ö–∞—Ç–µ–≥–æ—Ä–∏—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                category = func_type
                if category not in validation_result["categories"]:
                    validation_result["categories"][category] = 0
                validation_result["categories"][category] += 1
                
                # –£—Ä–æ–≤–µ–Ω—å –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
                security_level = func_data.get('security_level', 'unknown')
                if security_level not in function_analysis["security_levels"]:
                    function_analysis["security_levels"][security_level] = 0
                function_analysis["security_levels"][security_level] += 1
                
                # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏
                if func_data.get('is_critical', False):
                    function_analysis["critical_functions"] += 1
                
                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–∫–ª—é—á–µ–Ω–∏–µ
                if func_data.get('auto_enable', False):
                    function_analysis["auto_enable_functions"] += 1
                
                # –≠–∫—Å—Ç—Ä–µ–Ω–Ω–æ–µ –ø—Ä–æ–±—É–∂–¥–µ–Ω–∏–µ
                if func_data.get('emergency_wake_up', False):
                    function_analysis["emergency_wake_functions"] += 1
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
                required_fields = ['function_id', 'name', 'function_type', 'status']
                for field in required_fields:
                    if field not in func_data:
                        if field not in function_analysis["missing_fields"]:
                            function_analysis["missing_fields"][field] = 0
                        function_analysis["missing_fields"][field] += 1
                        validation_result["warnings"].append(f"–§—É–Ω–∫—Ü–∏—è {func_id} –Ω–µ –∏–º–µ–µ—Ç –ø–æ–ª—è {field}")
            
            # –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
            validation_result["data_quality"] = {
                "completeness_score": round((function_analysis["valid_functions"] / validation_result["total_functions"]) * 100, 2) if validation_result["total_functions"] > 0 else 0,
                "average_fields_per_function": round(sum(len(func) for func in functions.values() if isinstance(func, dict)) / validation_result["total_functions"], 2) if validation_result["total_functions"] > 0 else 0,
                "functions_with_all_required_fields": validation_result["total_functions"] - sum(function_analysis["missing_fields"].values()),
                "critical_functions_percentage": round((function_analysis["critical_functions"] / validation_result["total_functions"]) * 100, 2) if validation_result["total_functions"] > 0 else 0
            }
            
            # –î–µ—Ç–∞–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            validation_result["validation_details"] = function_analysis
            
        except json.JSONDecodeError as e:
            validation_result["errors"].append(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {str(e)}")
            validation_result["json_structure"]["is_valid_json"] = False
        except Exception as e:
            validation_result["errors"].append(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {str(e)}")
        
        return validation_result

    def count_security_files(self) -> Tuple[int, int]:
        """–ü–æ–¥—Å—á–µ—Ç —Ñ–∞–π–ª–æ–≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
        try:
            # –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ Python —Ñ–∞–π–ª–æ–≤ –≤ security –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            cmd = [
                "find", str(self.security_dir), "-name", "*.py",
                "-not", "-path", "*/backup*", "-not", "-path", "*/test*",
                "-not", "-path", "*/tests*", "-not", "-path", "*/logs*",
                "-not", "-path", "*/formatting_work*"
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            if result.returncode == 0:
                files = [f for f in result.stdout.strip().split('\n') if f.strip()]
                file_count = len(files)
            else:
                file_count = 0
            
            # –ü–æ–¥—Å—á–µ—Ç —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞
            cmd_lines = cmd + ["-exec", "wc", "-l", "{}", "+"]
            result_lines = subprocess.run(cmd_lines, capture_output=True, text=True, timeout=30)
            if result_lines.returncode == 0:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Ç—Ä–æ–∫–∏ –≤—ã–≤–æ–¥–∞ wc
                lines_output = result_lines.stdout.strip().split('\n')
                if lines_output and 'total' in lines_output[-1].lower():
                    total_lines = int(lines_output[-1].split()[0])
                else:
                    total_lines = 0
            else:
                total_lines = 0
            
            return file_count, total_lines
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–¥—Å—á–µ—Ç–∞ —Ñ–∞–π–ª–æ–≤: {e}")
            return 0, 0

    def analyze_architecture_by_categories(self) -> Dict[str, Dict]:
        """–ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
        categories_stats = {}
        
        for category_key, category_info in self.security_categories.items():
            if category_key == "other_security":
                continue
                
            category_path = self.project_root / category_info["path"]
            if not category_path.exists():
                continue
            
            try:
                # –ü–æ–¥—Å—á–µ—Ç —Ñ–∞–π–ª–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                cmd = [
                    "find", str(category_path), "-name", "*.py",
                    "-not", "-path", "*/backup*", "-not", "-path", "*/test*"
                ]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
                
                if result.returncode == 0:
                    files = [f for f in result.stdout.strip().split('\n') if f.strip()]
                    file_count = len(files)
                else:
                    file_count = 0
                
                # –ü–æ–¥—Å—á–µ—Ç —Å—Ç—Ä–æ–∫ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                cmd_lines = cmd + ["-exec", "wc", "-l", "{}", "+"]
                result_lines = subprocess.run(cmd_lines, capture_output=True, text=True, timeout=30)
                
                if result_lines.returncode == 0:
                    lines_output = result_lines.stdout.strip().split('\n')
                    if lines_output and 'total' in lines_output[-1].lower():
                        lines_count = int(lines_output[-1].split()[0])
                    else:
                        lines_count = 0
                else:
                    lines_count = 0
                
                categories_stats[category_key] = {
                    "name": category_info["name"],
                    "files": file_count,
                    "lines": lines_count,
                    "percentage": 0  # –ë—É–¥–µ—Ç —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–æ –ø–æ–∑–∂–µ
                }
                
            except Exception as e:
                categories_stats[category_key] = {
                    "name": category_info["name"],
                    "files": 0,
                    "lines": 0,
                    "percentage": 0
                }
        
        return categories_stats

    def run_flake8_analysis(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞ —Å flake8"""
        try:
            cmd = [
                "flake8", str(self.security_dir), "--count", "--statistics",
                "--exclude=backup,test,tests,logs,formatting_work,__pycache__"
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0:
                return {
                    "total_errors": 0,
                    "critical_errors": 0,
                    "line_length_errors": 0,
                    "errors_per_kloc": 0.0,
                    "quality_level": "A+",
                    "status": "clean"
                }
            
            # –ü–∞—Ä—Å–∏–Ω–≥ –≤—ã–≤–æ–¥–∞ flake8
            output_lines = result.stdout.strip().split('\n')
            total_errors = 0
            critical_errors = 0
            line_length_errors = 0
            
            for line in output_lines:
                if 'E9' in line or 'F' in line:
                    critical_errors += 1
                if 'E501' in line:
                    line_length_errors += 1
                if any(char.isdigit() for char in line):
                    try:
                        errors_in_line = int(line.split()[-1])
                        total_errors += errors_in_line
                    except (ValueError, IndexError):
                        pass
            
            # –ü–æ–ª—É—á–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ KLOC
            file_count, total_lines = self.count_security_files()
            kloc = total_lines / 1000 if total_lines > 0 else 1
            errors_per_kloc = total_errors / kloc if kloc > 0 else 0
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –∫–∞—á–µ—Å—Ç–≤–∞
            if errors_per_kloc <= 1.0:
                quality_level = "A+"
            elif errors_per_kloc <= 2.0:
                quality_level = "A"
            elif errors_per_kloc <= 5.0:
                quality_level = "B"
            elif errors_per_kloc <= 10.0:
                quality_level = "C"
            else:
                quality_level = "D"
            
            return {
                "total_errors": total_errors,
                "critical_errors": critical_errors,
                "line_length_errors": line_length_errors,
                "errors_per_kloc": errors_per_kloc,
                "quality_level": quality_level,
                "status": "has_errors" if total_errors > 0 else "clean"
            }
            
        except Exception as e:
            return {
                "total_errors": 0,
                "critical_errors": 0,
                "line_length_errors": 0,
                "errors_per_kloc": 0.0,
                "quality_level": "Unknown",
                "status": f"error: {str(e)}"
            }

    def calculate_excluded_files(self) -> Tuple[int, int]:
        """–ü–æ–¥—Å—á–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏ —Å—Ç—Ä–æ–∫"""
        try:
            # –ü–æ–¥—Å—á–µ—Ç –≤—Å–µ—Ö Python —Ñ–∞–π–ª–æ–≤ (–≤–∫–ª—é—á–∞—è –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ)
            cmd_all = ["find", str(self.security_dir), "-name", "*.py"]
            result_all = subprocess.run(cmd_all, capture_output=True, text=True, timeout=30)
            
            if result_all.returncode != 0:
                return 0, 0
            
            all_files = [f for f in result_all.stdout.strip().split('\n') if f.strip()]
            all_file_count = len(all_files)
            
            # –ü–æ–¥—Å—á–µ—Ç —Å—Ç—Ä–æ–∫ –≤–æ –≤—Å–µ—Ö —Ñ–∞–π–ª–∞—Ö
            cmd_all_lines = cmd_all + ["-exec", "wc", "-l", "{}", "+"]
            result_all_lines = subprocess.run(cmd_all_lines, capture_output=True, text=True, timeout=30)
            
            if result_all_lines.returncode != 0:
                return all_file_count, 0
            
            lines_output = result_all_lines.stdout.strip().split('\n')
            if lines_output and 'total' in lines_output[-1].lower():
                all_lines = int(lines_output[-1].split()[0])
            else:
                all_lines = 0
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –∏ —Å—Ç—Ä–æ–∫ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
            security_files, security_lines = self.count_security_files()
            
            excluded_files = all_file_count - security_files
            excluded_lines = all_lines - security_lines
            
            return excluded_files, excluded_lines
            
        except Exception:
            return 0, 0

    def generate_comprehensive_report(self) -> None:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        print("üîç –ê–Ω–∞–ª–∏–∑ —Å–∏—Å—Ç–µ–º—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ ALADDIN...")
        print("  üìä –í–∞–ª–∏–¥–∞—Ü–∏—è SFM —Ä–µ–µ—Å—Ç—Ä–∞...")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è SFM
        sfm_validation = self.validate_sfm_registry()
        
        print("  üìä –ü–æ–¥—Å—á–µ—Ç —Ñ–∞–π–ª–æ–≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏...")
        file_count, total_lines = self.count_security_files()
        kloc = total_lines / 1000
        
        print("  üìä –ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º...")
        categories_stats = self.analyze_architecture_by_categories()
        
        print("  üìä –ü–æ–¥—Å—á–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤...")
        excluded_files, excluded_lines = self.calculate_excluded_files()
        
        print("  üîç –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞...")
        quality_analysis = self.run_flake8_analysis()
        
        # –†–∞—Å—á–µ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        total_security_lines = sum(cat["lines"] for cat in categories_stats.values())
        for category in categories_stats.values():
            if total_security_lines > 0:
                category["percentage"] = (category["lines"] / total_security_lines) * 100
        
        print("=" * 80)
        print("üéØ –ü–û–õ–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ò–°–¢–ï–ú–´ –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò ALADDIN")
        print("=" * 80)
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        print("üìä –û–°–ù–û–í–ù–´–ï –ú–ï–¢–†–ò–ö–ò:")
        print(f"  ‚Ä¢ Python —Ñ–∞–π–ª–æ–≤: {file_count:,}")
        print(f"  ‚Ä¢ –°—Ç—Ä–æ–∫ –∫–æ–¥–∞: {total_lines:,}")
        print(f"  ‚Ä¢ KLOC: {kloc:.1f}")
        print(f"  ‚Ä¢ –ò—Å–∫–ª—é—á–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {excluded_files}")
        print(f"  ‚Ä¢ –ò—Å–∫–ª—é—á–µ–Ω–æ —Å—Ç—Ä–æ–∫: {excluded_lines:,}")
        
        # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        print("\nüèóÔ∏è –ê–†–•–ò–¢–ï–ö–¢–£–†–ê –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
        for category in categories_stats.values():
            print(f"  {category['name']:<25} | {category['files']:>3} —Ñ–∞–π–ª–æ–≤ | {category['lines']:>6,} —Å—Ç—Ä–æ–∫ | {category['percentage']:>5.1f}%")
        
        # SFM —Ñ—É–Ω–∫—Ü–∏–∏
        print(f"\nüîß SFM –§–£–ù–ö–¶–ò–ò:")
        print(f"  ‚Ä¢ –í—Å–µ–≥–æ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–æ: {sfm_validation['total_functions']}")
        print(f"  ‚Ä¢ –ê–∫—Ç–∏–≤–Ω—ã–µ: {sfm_validation['active_functions']}")
        print(f"  ‚Ä¢ –°–ø—è—â–∏–µ: {sfm_validation['sleeping_functions']}")
        print(f"  ‚Ä¢ –û—Ç–∫–ª—é—á–µ–Ω–Ω—ã–µ: {sfm_validation['disabled_functions']}")
        print(f"  ‚Ä¢ –°—Ç–∞—Ç—É—Å –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {'‚úÖ –í–ê–õ–ò–î–ï–ù' if sfm_validation['is_valid'] else '‚ùå –û–®–ò–ë–ö–ò'}")
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–µ —Ä–µ–µ—Å—Ç—Ä–∞
        if sfm_validation['file_info']:
            file_info = sfm_validation['file_info']
            print(f"\nüìÅ –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –†–ï–ï–°–¢–†–ï:")
            print(f"  ‚Ä¢ –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É: {file_info['file_path']}")
            print(f"  ‚Ä¢ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_info['file_size_kb']} KB ({file_info['file_size_mb']} MB)")
            print(f"  ‚Ä¢ –ü–æ—Å–ª–µ–¥–Ω–µ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ: {file_info['last_modified']}")
            print(f"  ‚Ä¢ –§–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {'‚úÖ' if file_info['file_exists'] else '‚ùå'}")
        
        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ JSON
        if sfm_validation['json_structure']:
            json_info = sfm_validation['json_structure']
            print(f"\nüîç –°–¢–†–£–ö–¢–£–†–ê JSON:")
            print(f"  ‚Ä¢ –í–∞–ª–∏–¥–Ω—ã–π JSON: {'‚úÖ' if json_info['is_valid_json'] else '‚ùå'}")
            print(f"  ‚Ä¢ –ï—Å—Ç—å –∫–ª—é—á 'functions': {'‚úÖ' if json_info['has_functions_key'] else '‚ùå'}")
            print(f"  ‚Ä¢ –ö–æ–¥–∏—Ä–æ–≤–∫–∞: {json_info['encoding']}")
            print(f"  ‚Ä¢ –ö–ª—é—á–∏ –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è: {', '.join(json_info['top_level_keys'])}")
        
        # –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
        if sfm_validation['data_quality']:
            quality = sfm_validation['data_quality']
            print(f"\nüìä –ö–ê–ß–ï–°–¢–í–û –î–ê–ù–ù–´–•:")
            print(f"  ‚Ä¢ –ü–æ–ª–Ω–æ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö: {quality['completeness_score']}%")
            print(f"  ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –ø–æ–ª–µ–π –Ω–∞ —Ñ—É–Ω–∫—Ü–∏—é: {quality['average_fields_per_function']}")
            print(f"  ‚Ä¢ –§—É–Ω–∫—Ü–∏–π —Å –ø–æ–ª–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏: {quality['functions_with_all_required_fields']}")
            print(f"  ‚Ä¢ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π: {quality['critical_functions_percentage']}%")
        
        # –î–µ—Ç–∞–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        if sfm_validation['validation_details']:
            details = sfm_validation['validation_details']
            print(f"\nüîç –î–ï–¢–ê–õ–ò –í–ê–õ–ò–î–ê–¶–ò–ò:")
            print(f"  ‚Ä¢ –í–∞–ª–∏–¥–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π: {details['valid_functions']}")
            print(f"  ‚Ä¢ –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π: {details['invalid_functions']}")
            print(f"  ‚Ä¢ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π: {details['critical_functions']}")
            print(f"  ‚Ä¢ –ê–≤—Ç–æ-–≤–∫–ª—é—á–µ–Ω–∏–µ: {details['auto_enable_functions']}")
            print(f"  ‚Ä¢ –≠–∫—Å—Ç—Ä–µ–Ω–Ω–æ–µ –ø—Ä–æ–±—É–∂–¥–µ–Ω–∏–µ: {details['emergency_wake_functions']}")
            
            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º
            if details['status_distribution']:
                print(f"  ‚Ä¢ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–æ–≤:")
                for status, count in sorted(details['status_distribution'].items()):
                    print(f"    - {status}: {count}")
            
            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —É—Ä–æ–≤–Ω—è–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
            if details['security_levels']:
                print(f"  ‚Ä¢ –£—Ä–æ–≤–Ω–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏:")
                for level, count in sorted(details['security_levels'].items()):
                    print(f"    - {level}: {count}")
        
        if sfm_validation['errors']:
            print(f"\n‚ùå –û–®–ò–ë–ö–ò –í–ê–õ–ò–î–ê–¶–ò–ò:")
            for error in sfm_validation['errors']:
                print(f"  ‚Ä¢ {error}")
        
        if sfm_validation['warnings']:
            print(f"\n‚ö†Ô∏è  –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–Ø –í–ê–õ–ò–î–ê–¶–ò–ò:")
            for warning in sfm_validation['warnings'][:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                print(f"  ‚Ä¢ {warning}")
            if len(sfm_validation['warnings']) > 10:
                print(f"  ‚Ä¢ ... –∏ –µ—â–µ {len(sfm_validation['warnings']) - 10} –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π")
        
        # –§—É–Ω–∫—Ü–∏–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        print(f"\nüìä –§–£–ù–ö–¶–ò–ò –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
        for category, count in sorted(sfm_validation['categories'].items()):
            print(f"  ‚Ä¢ {category:<25} : {count:>3} —Ñ—É–Ω–∫—Ü–∏–π")
        
        # –ö–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞
        print(f"\nüîç –ö–ê–ß–ï–°–¢–í–û –ö–û–î–ê:")
        print(f"  ‚Ä¢ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏: {quality_analysis['critical_errors']}")
        print(f"  ‚Ä¢ –û—à–∏–±–∫–∏ –¥–ª–∏–Ω—ã —Å—Ç—Ä–æ–∫: {quality_analysis['line_length_errors']}")
        print(f"  ‚Ä¢ –í—Å–µ–≥–æ –æ—à–∏–±–æ–∫: {quality_analysis['total_errors']}")
        print(f"  ‚Ä¢ –û—à–∏–±–æ–∫/KLOC: {quality_analysis['errors_per_kloc']:.2f}")
        print(f"  ‚Ä¢ –£—Ä–æ–≤–µ–Ω—å –∫–∞—á–µ—Å—Ç–≤–∞: {quality_analysis['quality_level']}")
        print(f"  ‚Ä¢ –°—Ç–∞—Ç—É—Å: {quality_analysis['status']}")
        
        # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏
        print(f"\nüèóÔ∏è –ê–†–•–ò–¢–ï–ö–¢–£–†–ù–´–ï –û–¶–ï–ù–ö–ò:")
        print(f"  ‚Ä¢ üèóÔ∏è  –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {self.architecture_scores['architecture']}/10 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê")
        print(f"  ‚Ä¢ üîó –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è: {self.architecture_scores['integration']}/10 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê")
        print(f"  ‚Ä¢ üîí –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: {self.architecture_scores['security']}/10 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê")
        print(f"  ‚Ä¢ üá∑üá∫ –†–æ—Å—Å–∏–π—Å–∫–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: {self.architecture_scores['russian_compliance']}/10 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê")
        print(f"  ‚Ä¢ üöÄ –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É: {self.architecture_scores['production_ready']}/10 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê")
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –º–∏—Ä–æ–≤—ã–º–∏ –ª–∏–¥–µ—Ä–∞–º–∏
        print(f"\nüèÜ –°–†–ê–í–ù–ï–ù–ò–ï –° –ú–ò–†–û–í–´–ú–ò –õ–ò–î–ï–†–ê–ú–ò:")
        print(f"  ‚Ä¢ ALADDIN: {kloc:.0f} KLOC ({quality_analysis['critical_errors']} –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫)")
        print(f"  ‚Ä¢ Norton 360: ~500 KLOC (–º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —É—è–∑–≤–∏–º–æ—Å—Ç–∏)")
        print(f"  ‚Ä¢ Kaspersky: ~800 KLOC (–ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ —É—è–∑–≤–∏–º–æ—Å—Ç–∏)")
        print(f"  ‚Ä¢ Bitdefender: ~600 KLOC (—Å—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å)")
        print(f"  ‚Ä¢ McAfee: ~700 KLOC (–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã)")
        
        # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        if quality_analysis['critical_errors'] > 0:
            print(f"\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏!")
        elif not sfm_validation['is_valid']:
            print(f"\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ü—Ä–æ–±–ª–µ–º—ã —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π SFM!")
        else:
            print(f"\n‚úÖ –°–ò–°–¢–ï–ú–ê –í –û–¢–õ–ò–ß–ù–û–ú –°–û–°–¢–û–Ø–ù–ò–ò!")
        
        print("=" * 80)

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    stats = ComprehensiveSecurityStats()
    stats.generate_comprehensive_report()

if __name__ == "__main__":
    main()