#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤ –≤ SFM —Ä–µ–µ—Å—Ç—Ä–µ
–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ —É–∫–∞–∑–∞–Ω—ã –≤ —Ä–µ–µ—Å—Ç—Ä–µ, –Ω–æ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –≤ —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ
"""

import json
import os
import sys
from pathlib import Path
from typing import Dict, List, Tuple
from datetime import datetime

def load_sfm_registry() -> Dict:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç SFM —Ä–µ–µ—Å—Ç—Ä –∏–∑ JSON —Ñ–∞–π–ª–∞"""
    registry_path = Path("data/sfm/function_registry.json")
    
    if not registry_path.exists():
        print(f"‚ùå –§–∞–π–ª —Ä–µ–µ—Å—Ç—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {registry_path}")
        return {}
    
    try:
        with open(registry_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data.get('functions', {})
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–µ—Å—Ç—Ä–∞: {e}")
        return {}

def normalize_path(file_path: str, base_dir: Path) -> Path:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –±–∞–∑–æ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
    if not file_path:
        return None
    
    # –£–±–∏—Ä–∞–µ–º ./ –≤ –Ω–∞—á–∞–ª–µ –µ—Å–ª–∏ –µ—Å—Ç—å
    if file_path.startswith('./'):
        file_path = file_path[2:]
    
    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å
    full_path = base_dir / file_path
    return full_path.resolve()

def check_file_exists(file_path: Path) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞"""
    if not file_path:
        return False
    return file_path.exists() and file_path.is_file()

def find_similar_files(missing_file: str, base_dir: Path) -> List[Path]:
    """–ò—â–µ—Ç –ø–æ—Ö–æ–∂–∏–µ —Ñ–∞–π–ª—ã –≤ —Å–∏—Å—Ç–µ–º–µ"""
    similar_files = []
    missing_name = Path(missing_file).name.lower()
    
    try:
        # –ò—â–µ–º —Ñ–∞–π–ª—ã —Å –ø–æ—Ö–æ–∂–∏–º–∏ –∏–º–µ–Ω–∞–º–∏
        for root, dirs, files in os.walk(base_dir):
            for file in files:
                if file.lower().endswith('.py'):
                    file_lower = file.lower()
                    if (missing_name in file_lower or 
                        file_lower.replace('_', '') in missing_name.replace('_', '') or
                        missing_name.replace('_', '') in file_lower.replace('_', '')):
                        similar_files.append(Path(root) / file)
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö —Ñ–∞–π–ª–æ–≤: {e}")
    
    return similar_files[:5]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∞–∫—Å–∏–º—É–º 5 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

def analyze_missing_files():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤"""
    print("üîç –ê–ù–ê–õ–ò–ó –û–¢–°–£–¢–°–¢–í–£–Æ–©–ò–• –§–ê–ô–õ–û–í –í SFM –†–ï–ï–°–¢–†–ï")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–µ—Å—Ç—Ä
    functions = load_sfm_registry()
    if not functions:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å SFM —Ä–µ–µ—Å—Ç—Ä")
        return
    
    base_dir = Path.cwd()
    missing_files = []
    existing_files = []
    similar_found = {}
    
    print(f"üìÅ –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {base_dir}")
    print(f"üìä –í—Å–µ–≥–æ —Ñ—É–Ω–∫—Ü–∏–π –≤ —Ä–µ–µ—Å—Ç—Ä–µ: {len(functions)}")
    print()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
    for func_id, func_data in functions.items():
        file_path_str = func_data.get('file_path', '')
        if not file_path_str:
            continue
            
        normalized_path = normalize_path(file_path_str, base_dir)
        
        if check_file_exists(normalized_path):
            existing_files.append((func_id, file_path_str, normalized_path))
        else:
            missing_files.append((func_id, file_path_str, normalized_path))
            
            # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ñ–∞–π–ª—ã
            similar = find_similar_files(file_path_str, base_dir)
            if similar:
                similar_found[func_id] = similar
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"‚úÖ –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã: {len(existing_files)}")
    print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã: {len(missing_files)}")
    print()
    
    if missing_files:
        print("üîç –û–¢–°–£–¢–°–¢–í–£–Æ–©–ò–ï –§–ê–ô–õ–´:")
        print("-" * 60)
        
        for i, (func_id, original_path, normalized_path) in enumerate(missing_files, 1):
            print(f"{i:3d}. {func_id}")
            print(f"     –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—É—Ç—å: {original_path}")
            print(f"     –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π:   {normalized_path}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ñ–∞–π–ª—ã
            if func_id in similar_found:
                print(f"     üîç –ü–æ—Ö–æ–∂–∏–µ —Ñ–∞–π–ª—ã –Ω–∞–π–¥–µ–Ω—ã:")
                for similar in similar_found[func_id]:
                    rel_path = similar.relative_to(base_dir)
                    print(f"        - {rel_path}")
            print()
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º —Ñ–∞–π–ª–æ–≤
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –¢–ò–ü–ê–ú –§–ê–ô–õ–û–í:")
    print("-" * 60)
    
    type_stats = {}
    for func_id, func_data in functions.items():
        func_type = func_data.get('function_type', 'unknown')
        file_path_str = func_data.get('file_path', '')
        
        if func_type not in type_stats:
            type_stats[func_type] = {'total': 0, 'missing': 0, 'existing': 0}
        
        type_stats[func_type]['total'] += 1
        
        if file_path_str:
            normalized_path = normalize_path(file_path_str, base_dir)
            if check_file_exists(normalized_path):
                type_stats[func_type]['existing'] += 1
            else:
                type_stats[func_type]['missing'] += 1
    
    for func_type, stats in sorted(type_stats.items()):
        missing_pct = (stats['missing'] / stats['total'] * 100) if stats['total'] > 0 else 0
        print(f"{func_type:20} | –í—Å–µ–≥–æ: {stats['total']:3d} | –°—É—â–µ—Å—Ç–≤—É—é—Ç: {stats['existing']:3d} | –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç: {stats['missing']:3d} ({missing_pct:5.1f}%)")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    report_data = {
        'timestamp': datetime.now().isoformat(),
        'base_directory': str(base_dir),
        'total_functions': len(functions),
        'existing_files': len(existing_files),
        'missing_files': len(missing_files),
        'missing_files_details': [
            {
                'function_id': func_id,
                'original_path': original_path,
                'normalized_path': str(normalized_path),
                'similar_files': [str(s) for s in similar_found.get(func_id, [])]
            }
            for func_id, original_path, normalized_path in missing_files
        ],
        'type_statistics': type_stats
    }
    
    report_path = f"data/reports/missing_files_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    os.makedirs(os.path.dirname(report_path), exist_ok=True)
    
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nüìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
    
    return missing_files, similar_found

if __name__ == "__main__":
    try:
        missing_files, similar_found = analyze_missing_files()
        print(f"\nüéØ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù")
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(missing_files)} –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤")
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(similar_found)} —Ñ—É–Ω–∫—Ü–∏–π —Å –ø–æ—Ö–æ–∂–∏–º–∏ —Ñ–∞–π–ª–∞–º–∏")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {e}")
        sys.exit(1)