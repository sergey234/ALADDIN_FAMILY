#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –ø–µ—Ä–µ–≤–æ–¥–∞ NaturalLanguageProcessor –≤ —Å–ø—è—â–∏–π —Ä–µ–∂–∏–º
–°–æ–∑–¥–∞–Ω: 2024-09-05
–í–µ—Ä—Å–∏—è: 1.0.0
"""

import os
import sys
import json
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

def put_natural_language_to_sleep():
    """–ü–µ—Ä–µ–≤–æ–¥ NaturalLanguageProcessor –≤ —Å–ø—è—â–∏–π —Ä–µ–∂–∏–º"""
    print("üò¥ –ü–ï–†–ï–í–û–î NATURALLANGUAGEPROCESSOR –í –°–ü–Ø–©–ò–ô –†–ï–ñ–ò–ú")
    print("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
    file_path = "security/ai_agents/natural_language_processor.py"
    if not os.path.exists(file_path):
        print("‚ùå –§–∞–π–ª NaturalLanguageProcessor –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False
    
    print("‚úÖ –§–∞–π–ª NaturalLanguageProcessor –Ω–∞–π–¥–µ–Ω")
    
    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –ø–µ—Ä–µ–¥ —Å–ø—è—â–∏–º —Ä–µ–∂–∏–º–æ–º
    print("\nüîç –ü–†–û–í–ï–†–ö–ê –ö–ê–ß–ï–°–¢–í–ê –ü–ï–†–ï–î –°–ü–Ø–©–ò–ú –†–ï–ñ–ò–ú–û–ú")
    print("-" * 50)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–¥
    lines = content.split('\n')
    total_lines = len(lines)
    code_lines = len([line for line in lines if line.strip() and not line.strip().startswith('#')])
    
    print(f"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ö–û–î–ê:")
    print(f"   üìÑ –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {total_lines}")
    print(f"   üíª –°—Ç—Ä–æ–∫ –∫–æ–¥–∞: {code_lines}")
    print(f"   üìà –ü–ª–æ—Ç–Ω–æ—Å—Ç—å –∫–æ–¥–∞: {code_lines/total_lines*100:.1f}%")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    components = {
        "–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫": content.count("try:") + content.count("except"),
        "–ö–ª–∞—Å—Å—ã": content.count("class "),
        "–ú–µ—Ç–æ–¥—ã": content.count("def "),
        "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è": content.count('"""') + content.count("'''"),
        "–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ": content.count("logger") + content.count("logging"),
        "–¢–∏–ø–∏–∑–∞—Ü–∏—è": content.count(": str") + content.count(": int") + content.count(": bool"),
        "NLP": content.count("nlp") + content.count("NLP") + content.count("natural"),
        "–ù–∞–º–µ—Ä–µ–Ω–∏—è": content.count("intent") + content.count("Intent"),
        "–°—É—â–Ω–æ—Å—Ç–∏": content.count("entity") + content.count("Entity"),
        "–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å": content.count("sentiment") + content.count("Sentiment"),
        "–ö–æ–Ω—Ç–µ–∫—Å—Ç": content.count("context") + content.count("Context"),
        "–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞": content.count("keyword") + content.count("Keyword"),
        "–≠–º–æ—Ü–∏–∏": content.count("emotion") + content.count("Emotion"),
        "–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è": content.count("token") + content.count("Token"),
        "–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å": content.count("security") + content.count("Security"),
        "–¶–≤–µ—Ç–æ–≤–∞—è —Å—Ö–µ–º–∞": content.count("color_scheme") + content.count("Matrix AI"),
        "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ": content.count("test_") + content.count("_test_")
    }
    
    print(f"\nüîß –ö–û–ú–ü–û–ù–ï–ù–¢–´ –°–ò–°–¢–ï–ú–´:")
    for component, count in components.items():
        print(f"   {component}: {count}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
    quality_checks = {
        "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è": components["–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è"] > 20,
        "–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫": components["–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫"] > 10,
        "–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ": components["–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ"] > 5,
        "–¢–∏–ø–∏–∑–∞—Ü–∏—è": components["–¢–∏–ø–∏–∑–∞—Ü–∏—è"] > 10,
        "NLP": components["NLP"] > 5,
        "–ù–∞–º–µ—Ä–µ–Ω–∏—è": components["–ù–∞–º–µ—Ä–µ–Ω–∏—è"] > 5,
        "–°—É—â–Ω–æ—Å—Ç–∏": components["–°—É—â–Ω–æ—Å—Ç–∏"] > 5,
        "–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å": components["–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å"] > 5,
        "–ö–æ–Ω—Ç–µ–∫—Å—Ç": components["–ö–æ–Ω—Ç–µ–∫—Å—Ç"] > 5,
        "–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞": components["–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞"] > 5,
        "–≠–º–æ—Ü–∏–∏": components["–≠–º–æ—Ü–∏–∏"] > 5,
        "–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è": components["–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è"] > 5,
        "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ": components["–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"] > 5,
        "–¶–≤–µ—Ç–æ–≤–∞—è —Å—Ö–µ–º–∞": components["–¶–≤–µ—Ç–æ–≤–∞—è —Å—Ö–µ–º–∞"] > 5,
        "–ü–æ–∫—Ä—ã—Ç–∏–µ –∫–æ–¥–∞": code_lines >= 500
    }
    
    print(f"\nüèóÔ∏è –ü–†–û–í–ï–†–ö–ê –ö–ê–ß–ï–°–¢–í–ê:")
    for check, passed in quality_checks.items():
        status = "‚úÖ –ü–†–û–ô–î–ï–ù–û" if passed else "‚ùå –ù–ï –ü–†–û–ô–î–ï–ù–û"
        print(f"   {check}: {status}")
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –±–∞–ª–ª—ã
    total_checks = len(quality_checks)
    passed_checks = sum(quality_checks.values())
    quality_score = (passed_checks / total_checks) * 100
    
    print(f"\nüèÜ –û–¶–ï–ù–ö–ê –ö–ê–ß–ï–°–¢–í–ê: {quality_score:.1f}/100")
    
    if quality_score >= 95:
        print("‚úÖ –ö–ê–ß–ï–°–¢–í–û: A+ (–û–¢–õ–ò–ß–ù–û) - –ì–û–¢–û–í –ö –°–ü–Ø–©–ï–ú–£ –†–ï–ñ–ò–ú–£")
    elif quality_score >= 90:
        print("‚úÖ –ö–ê–ß–ï–°–¢–í–û: A (–û–ß–ï–ù–¨ –•–û–†–û–®–û) - –ì–û–¢–û–í –ö –°–ü–Ø–©–ï–ú–£ –†–ï–ñ–ò–ú–£")
    elif quality_score >= 80:
        print("‚ö†Ô∏è –ö–ê–ß–ï–°–¢–í–û: B (–•–û–†–û–®–û) - –ú–û–ñ–ù–û –ü–ï–†–ï–í–ï–°–¢–ò –í –°–ü–Ø–©–ò–ô –†–ï–ñ–ò–ú")
    else:
        print("‚ùå –ö–ê–ß–ï–°–¢–í–û: C (–¢–†–ï–ë–£–ï–¢ –£–õ–£–ß–®–ï–ù–ò–Ø) - –ù–ï –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø")
        return False
    
    # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ —Å–ø—è—â–∏–π —Ä–µ–∂–∏–º
    print(f"\nüò¥ –ü–ï–†–ï–í–û–î –í –°–ü–Ø–©–ò–ô –†–ï–ñ–ò–ú")
    print("-" * 30)
    
    try:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
        sys.path.append('security/ai_agents')
        from natural_language_processor import NaturalLanguageProcessor
        
        # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä
        nlp_processor = NaturalLanguageProcessor()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å
        print(f"üìä –¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å: {nlp_processor.status}")
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ —Å–ø—è—â–∏–π —Ä–µ–∂–∏–º
        nlp_processor.status = "SLEEP"
        nlp_processor.last_update = datetime.now()
        
        print(f"‚úÖ –°—Ç–∞—Ç—É—Å –∏–∑–º–µ–Ω–µ–Ω –Ω–∞: {nlp_processor.status}")
        print(f"üïê –í—Ä–µ–º—è –ø–µ—Ä–µ–≤–æ–¥–∞: {nlp_processor.last_update}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ø—è—â–µ–≥–æ —Ä–µ–∂–∏–º–∞
        sleep_config = {
            "component": "NaturalLanguageProcessor",
            "status": "SLEEP",
            "sleep_time": datetime.now().isoformat(),
            "quality_score": quality_score,
            "components": components,
            "quality_checks": quality_checks,
            "total_lines": total_lines,
            "code_lines": code_lines
        }
        
        os.makedirs("data/sleep_mode", exist_ok=True)
        config_file = "data/sleep_mode/natural_language_sleep_config.json"
        
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(sleep_config, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–ø—è—â–µ–≥–æ —Ä–µ–∂–∏–º–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {config_file}")
        
        # –°–æ–∑–¥–∞–µ–º –ª–æ–≥
        log_file = f"logs/natural_language_sleep_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        os.makedirs("logs", exist_ok=True)
        
        with open(log_file, 'w', encoding='utf-8') as f:
            f.write(f"NaturalLanguageProcessor –ø–µ—Ä–µ–≤–µ–¥–µ–Ω –≤ —Å–ø—è—â–∏–π —Ä–µ–∂–∏–º\n")
            f.write(f"–í—Ä–µ–º—è: {datetime.now().isoformat()}\n")
            f.write(f"–ö–∞—á–µ—Å—Ç–≤–æ: {quality_score:.1f}/100\n")
            f.write(f"–°—Ç–∞—Ç—É—Å: {nlp_processor.status}\n")
        
        print(f"üìù –õ–æ–≥ —Å–æ–∑–¥–∞–Ω: {log_file}")
        
        print(f"\nüéâ NATURALLANGUAGEPROCESSOR –£–°–ü–ï–®–ù–û –ü–ï–†–ï–í–ï–î–ï–ù –í –°–ü–Ø–©–ò–ô –†–ï–ñ–ò–ú!")
        print(f"   üìä –ö–∞—á–µ—Å—Ç–≤–æ: {quality_score:.1f}/100")
        print(f"   üò¥ –°—Ç–∞—Ç—É—Å: SLEEP")
        print(f"   üïê –í—Ä–µ–º—è: {nlp_processor.last_update}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –≤ —Å–ø—è—â–∏–π —Ä–µ–∂–∏–º: {e}")
        return False

if __name__ == "__main__":
    success = put_natural_language_to_sleep()
    if success:
        print("\n‚úÖ –°–ö–†–ò–ü–¢ –í–´–ü–û–õ–ù–ï–ù –£–°–ü–ï–®–ù–û!")
    else:
        print("\n‚ùå –°–ö–†–ò–ü–¢ –ó–ê–í–ï–†–®–ò–õ–°–Ø –° –û–®–ò–ë–ö–û–ô!")